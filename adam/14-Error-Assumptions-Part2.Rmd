---
title: "Checking Error Assumptions Part 2"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  html_document:
    df_print: paged
  pdf_document: null
---

```{r}
library(car)
```

# Motivating Example

The dataset `savings` in the `faraway` package contains savings data from 50 different countries. The variables in the dataset are: 

- `sr` is the savings rate, personal saving divided by disposable income.
- `pop15` is the percent of the population under age of 15.
- `pop75` is the percent of the population over age of 75.
- `dpi` is the per-capita disposable income in dollars.
- `ddpi` is the percent growth rate of dpi.


```{r}
data(savings, package = "faraway") # load data
lmod <- lm(sr ~ ., data = savings) #fit full model
faraway::sumary(lmod)
```

# Standard Assumptions Revisited

There are several standard assumptions made when performing linear regression.

## Theoretical Properties 

The ones related to theoretical properties:

1. $E( \mathbf{y} \ | \ X ) = X \boldsymbol\beta$.
2. 	$\epsilon_1, \epsilon_2, \ldots , \epsilon_n \overset{\mbox{i.i.d.}}{\sim} N(0, \sigma^2)$.

      a. $E(\epsilon \ | \ \mathbb{X} )$ (essentially same as first condition).
      b. $\mbox{Var}(\epsilon \ | \ \mathbb{X} ) = \sigma^2$.
      c. $\mbox{Cov}( \epsilon_i , \epsilon_j \ | \ \mathbb{X}) = 0$ for all $i \ne j$
      d. Each of the errors, regardless of the regressor values, are normally distributed

## Practical Considerations

3. The columns of $X$ are linearly independent, i.e., none of the regressors are linear combinations of each other. This assumption is checking by assessing **whether collinearity is present**. This assumption is critical for ensuring that our model is identifiable (estimable).

4. **No observations are substantially more influential than other observations** in determining the fit of the model to the observed data. Influential observations can make it difficult to determine whether Assumptions 1 and 2 are satisfied.

## Standard Assumptions Prioritized

We assume that any issues with collinearity and identifiability (Assumption 3) have already been addressed. We have discussed this process.

1.	**The structure of the model is correct (Assumption 1).** Which regressors should be included/excluded. Should we transform any predictors? The response? 
2.	**No points are overly influential in determining the model fit (Assumption 4).** An overly influential observation can make it seem like the model is correctly specified when it is not.
3. **The errors have constant variance (Assumption 2).**  If this assumption isnâ€™t satisfied, then standard confidence intervals for the regression coefficients and mean function and prediction intervals for new observations are not trustworthy.
4. **The errors are uncorrelated (Assumption 2).**
5. **The errors are normally distributed (Assumption 2).** 

- This is the least important assumption. If the previous assumptions are satisfied, then our OLS estimator of $\beta$ is still the best linear unbiased estimator regardless of the normality of the errors.
- If the sample size is large enough, the central limit theorem tells us that our confidence intervals for the regression coefficients and the mean function are still approximately valid. 
- However, if our sample size is small or we are interested in constructing a prediction interval, then non-normal errors can lead to untrustworthy confidence and prediction intervals.


```{r fig 1, fig.width=8, fig.height=6}
par(mfrow = c(2, 2))

# plot of residuals versus fitted values
residualPlot(lmod, quadratic = FALSE) # We do not want to draw the quad reg

# plot of residuals versus fitted values
plot(lmod, which = 1) 

# plot sqrt absolute value of residuals vs fitted values
plot(sqrt(abs(residuals(lmod))) ~ fitted(lmod), xlab = "fitted", 
     ylab= expression(sqrt(hat(epsilon)))) 

# plot of Standardized residuals versus fitted values
plot(lmod, which = 3) 
par(mfrow = c(1, 1))
```


- **Expected value of error is zero.** Residuals look like a cloud of points with a value of zero splitting the points into approximately two mirror images above and below zero.
- **Constant variance assumption looks good.** Equally wide spread of residual values regardless of the fitted value.

```{r fig2, fig.width=8, fig.height=6}
# plot of residuals versus predictors
residualPlots(lmod, quadratic = FALSE, fitted = FALSE, tests = FALSE)
```

- We see similar properties (expected value zero and constant mean) in the residual plots against each regressor.

### Running a Statistical Test

- H~0~: The variance of the residuals for `Pop15` $> 35$ and `Pop15` $< 35$ are the same. The ratio of the two variances is equal to 1.
- H~a~: The variance of the residuals for `Pop15` $> 35$  and `Pop15`$< 35$ are NOT the same. The ratio of the two variances is NOT equal to 1.


```{r}
var.test(residuals(lmod)[savings$pop15 > 35], residuals(lmod)[savings$pop15 < 35])
```

# Checking Normality of Residuals

- Tests and confidence intervals are based on the assumption that the errors are normally distributed.


- We seem to have detected an issue. 
- This test does not tell us how to fix it!
- Maybe construct two different models? Maybe a transformation of the variables will address this issue?

When the errors are nonnormal:

- Estimates will still be unbiased (assuming the model is correct and the error mean is zero).
- Tests and confidence intervals will not be exact, but the central limit theorem says that the intervals and tests will be increasingly accurate as the sample size increases.
- The consequences can generally be ignored for short-tailed distributions.
- For skewed errors, a transformation may solve the problem.
- For heavy-tailed errors, it is best to use robust methods that give less weight to outlying observations.
- You may go back to step 1 and maybe consider a different model, though the problem may not be present in a different model.


## Q-Q Plots

- **q-q plots** are great plots for checking the normality assumption.
- On the x-axis goes z-scores for the sorted residuals (if they were normally distributed)
- A reference line is often plotted for comparison with $N(0,1)$
- If the residuals are distributed similarly to observations coming from a normal distribution, then the points of a q-q plot will lie approximately in a straight line at a $45^{\circ}$ angle.


```{r}
# Using base R
qqnorm(residuals(lmod), ylab = "Residuals")
qqline(residuals(lmod))
```


- We can plot the residuals from the summary output we stored in `lmod`. This will produce a q-q plot for the **standardized residuals**, along with a helpful reference line.

```{r}
plot(lmod, which = 2)
```

- The ``car::qqPlot` function is q-q plot for the **studentized residuals**, along with pointwise confidence bands for what is expected if $\boldsymbol\epsilon \sim N(0, \sigma^2 I)$.


```{r}
# Using car package
qqPlot(lmod) 
```


### Interpreting q-q Plots

If the marked points are:

- **Flatter than the line**, there is less data than we'd have if normal
- **Steeper than the line**, there is more data than we'd have if normal.



```{r, eval = FALSE, echo=FALSE}
set.seed(53)
qqPlot(rnorm(50), ylab = "observed data",
       xlab = "normal quantiles", main = "Sample 1")
#hist(rnorm(50), ylab = "frequency",
#       xlab = "observed data", main = "Sample 1")
```

```{r, eval = FALSE, echo=FALSE}
set.seed(53)
qqPlot(exp(rnorm(50)), ylab = "observed data",
       xlab = "normal quantiles", main = "Sample 2") 
#hist(exp(rnorm(50)), ylab = "frequency",
#       xlab = "observed data", main = "Sample 2")
```

```{r, eval = FALSE, echo=FALSE}
set.seed(53)
qqPlot(rcauchy(50), ylab = "observed data",
       xlab = "normal quantiles", main = "Sample 3")
hist(rcauchy(50), ylab = "frequency", breaks = 20,
       xlab = "observed data", main = "Sample 3")
```

```{r, eval = FALSE, echo=FALSE}
set.seed(53)
qqPlot(runif(50), ylab = "observed data",
       xlab = "normal quantiles", main = "Sample 4")
hist(runif(50), ylab = "frequency", breaks = 20,
       xlab = "observed data", main = "Sample 4")
```

```{r, eval = FALSE, echo=FALSE}
set.seed(53)
qqPlot(rexp(50), ylab = "observed data",
       xlab = "normal quantiles", main = "Sample 5")
hist(rexp(50), ylab = "frequency", breaks = 20,
       xlab = "observed data", main = "Sample 5")
```


## The Shapiro-Wilk test for Normality

A formal test of normality can be performed using the **Shapiro-Wilk test**.  

- The null hypothesis of the Shapiro-Wilk test is that the residuals are a random sample from a normal distribution.  
- The alternative is that the residuals are not a sample from a normal distribution.
- `shapiro.test(residuals(lmod))` will perform a Shapiro-Wilk test.
- A statistical decision is made using the usual approach with $p$-values.  

```{r}
shapiro.test(residuals(lmod)) # Shapiro-Wilk test.
```

## Question 1: Interpret the result of this test in practical terms.

**Enter Your Response Here**

While the Shapiro-Wilk test is a tidy way to assess normality, it is not as flexible as the q-q plot.

- It does not suggest a way to correct the problem.
- It is easily influenced by the number of observations so that even minor departures from normality are detected, even when there is little reason to abandon the least squares approach.

# Checking for Correlated Errorrs

- It is difficult to check for correlated errors because there are so many possible patterns of correlation that may occur.
  - The structure of temporal or spatial data makes this easier to check.
- If the errors $\boldsymbol\epsilon$ are uncorrelated, then the residuals $\hat{\boldsymbol\epsilon}$ are typically close to uncorrelated.


## Motivating Example: Global warming

The dataset `faraway::globwarm` consists of 1001 observations related to the average northern hemisphere temperature from 1856-2000 and eight climate proxies from 1000-2000 AD. Data can be used to predict temperatures prior to 1856.

```{r}
data(globwarm, package = "faraway")
#summary(globwarm)
```


- This is **temporal** data since each observation has an associated time (`year`). 
- There are 856 observations prior to 1856 that are missing `nhtemp` values.
  - By default, these observations are omitted from our model (by R)

```{r}
# We exclude year from the model but include all other regressors
lmod2 <- lm(nhtemp ~ . - year, data = globwarm)
faraway::sumary(lmod2)
```

## Plotting Residuals Against Time

If the errors are uncorrelated, we expect a random scatter of points around $\hat{\epsilon}=0$.

```{r}
# residuals vs time
plot(residuals(lmod2) ~ year, 
     data = na.omit(globwarm), ylab = "residuals")
abline(h = 0)
```

## Question 2: Do you notice any correlation in the errors?

**Enter Your Response Here**

## Plotting Successive Pairs of Residuals

Another approach to check for serial correlation is to plot successive pairs of residuals.

```{r}
n = nobs(lmod2)
plot(tail(residuals(lmod2), n - 1) ~      # extracts (e_1, e_2, ..., e_49)
      head(residuals(lmod2), n - 1),      # extracts (e_2, e_3, ..., e_50)
     xlab = expression(hat(epsilon)[i]),
     ylab =expression(hat(epsilon)[i+1]))
abline(h= 0 , v = 0, col = grey(0.75))
```

## Question 3: Interpret the plot above. How does this confirm a positive serial correlation?

**Enter Your Response Here**

## The Durbin-Watson Test for Uncorrelated Errors 

A formal test for serial correlation between residuals can be performed using the **Durbin-Watson test**.  


- Let $\rho$ denote the temporal correlation between residuals.
  - H~0~: The residuals are uncorrelated, $\rho = 0$.
  - H~a~: The residuals are related in some way ($\rho = 0$, $\rho > 0$, or $\rho < 0$).
- The test statistic is:

$$DW = \frac{\sum_{i=2}^n(\hat{\epsilon}_i - \hat{\epsilon}_{i-1})^2}{\sum_{i=1}^n \hat{\epsilon}_i^2}$$

- The test can be implemented in the `lmtest` package.

```{r}
library(lmtest)
dwtest(lmod2, alternative = "greater") # note greater is the default
```

## Question 4: Interpret the result of this test in practical terms.

**Enter Your Response Here**

- **Generalized least squares** (which takes into account dependence) can be used for data with correlated errors.
- When there is no apparent temporal or spatial link between observations, it is almost impossible to check for correlation between errors.	On the other hand, there is generally no reason to suspect it either!

# Practice Example: A Model for SAT Scores  

1. Using the `sat` dataset in the `faraway` package, fit a model with the total SAT score as the response and `expend`, `salary`, `ratio`, and `takers` as predictors. 


2. Perform regression diagnostics on this model to answer the following questions. 

  a. Check the mean-zero error assumption.
  b. Check the constant error variance assumption.
  c. Check the normal error assumption. 
  d. Should we check for correlated errors?


# Summary of Methods for Checking Error Assumptions

**Mean-zero error assumption**: 

- Plot of residuals versus fitted values

**Constant error variance assumption**:

- Plot of residuals versus fitted values
- Plot of $\sqrt{| \hat{\epsilon} |}$ versus fitted values.
- Plot of standardized residuals versus fitted values.
- Plot of residuals versus each regressor.
	
	
**Normal error assumption**:

- q-q of residuals
- Shapiro-Wilk test

**Autocorrelated errors**:

- Plot of residuals versus time
- Plot of successive pairs of residuals
- Durbin-Watson test


# Summary of useful R functions for checking error assumptions

## Residuals:

- `residuals(lmod)` extracts the OLS residuals.
- `rstandard(lmod)` extracts the standardized residuals.
- `rstudent(lmod)` extracts the studentized residuals.

## Mean-zero error assumption:

- `car::residualPlot` constructs a plot of the residuals versus fitted values.
- `plot(lmod, which = 1)` constructs a plot of the residuals versus fitted values.

## Constant error variance assumption:

- `car::residualPlots` constructs a plots of the residuals versus each predictor and the residuals versus the fitted values.
- `plot(lmod, which = 3)` constructs a plot of **square root of standardized residuals** versus the fitted values to increase resolution.

## To assess error normality: 

- `car::qqPlot(lmod)` will produce a q-q plot for the **studentized residuals**, along with the appropriate t-based, pointwise confidence bands for what is expected if $\boldsymbol\epsilon \sim N(0, \sigma^2 I)$.
- `plot(lmod, which = 2)` will produce a q-q plot for the **standardized residuals**, along with a helpful reference line.
- `shapiro.test(residuals(lmod))` performs a Shapiro-Wilk test on the residuals.

## Correlated Errors

- `lmtest::dwtest` performs a Durbin-Watson test on the residuals of a fitted model

