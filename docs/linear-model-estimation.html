<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Linear model estimation | Joshua French</title>
  <meta name="description" content="A collection of R notebooks demonstrating how to perform data analysis with linear regression." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Linear model estimation | Joshua French" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A collection of R notebooks demonstrating how to perform data analysis with linear regression." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Linear model estimation | Joshua French" />
  
  <meta name="twitter:description" content="A collection of R notebooks demonstrating how to perform data analysis with linear regression." />
  

<meta name="author" content="Chapter 6 Linear model estimation | Joshua French" />


<meta name="date" content="2022-01-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="defining-and-fitting-a-linear-model.html"/>
<link rel="next" href="parameter-estimation-for-linear-models.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis with Linear Regression</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminaries</a></li>
<li class="chapter" data-level="1" data-path="r-foundations.html"><a href="r-foundations.html"><i class="fa fa-check"></i><b>1</b> R Foundations</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-foundations.html"><a href="r-foundations.html#what-is-r"><i class="fa fa-check"></i><b>1.1</b> What is R?</a></li>
<li class="chapter" data-level="1.2" data-path="r-foundations.html"><a href="r-foundations.html#where-to-get-r-and-r-studio-desktop"><i class="fa fa-check"></i><b>1.2</b> Where to get R (and R Studio Desktop)</a></li>
<li class="chapter" data-level="1.3" data-path="r-foundations.html"><a href="r-foundations.html#r-studio-layout"><i class="fa fa-check"></i><b>1.3</b> R Studio Layout</a></li>
<li class="chapter" data-level="1.4" data-path="r-foundations.html"><a href="r-foundations.html#running-code-scripts-and-comments"><i class="fa fa-check"></i><b>1.4</b> Running code, scripts, and comments</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="r-foundations.html"><a href="r-foundations.html#example"><i class="fa fa-check"></i><b>1.4.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="r-foundations.html"><a href="r-foundations.html#packages"><i class="fa fa-check"></i><b>1.5</b> Packages</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="r-foundations.html"><a href="r-foundations.html#example-1"><i class="fa fa-check"></i><b>1.5.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="r-foundations.html"><a href="r-foundations.html#getting-help"><i class="fa fa-check"></i><b>1.6</b> Getting help</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="r-foundations.html"><a href="r-foundations.html#example-2"><i class="fa fa-check"></i><b>1.6.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="r-foundations.html"><a href="r-foundations.html#data-types-and-structures"><i class="fa fa-check"></i><b>1.7</b> Data types and structures</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="r-foundations.html"><a href="r-foundations.html#basic-data-types"><i class="fa fa-check"></i><b>1.7.1</b> Basic data types</a></li>
<li class="chapter" data-level="1.7.2" data-path="r-foundations.html"><a href="r-foundations.html#other-important-object-types"><i class="fa fa-check"></i><b>1.7.2</b> Other important object types</a></li>
<li class="chapter" data-level="1.7.3" data-path="r-foundations.html"><a href="r-foundations.html#data-structures"><i class="fa fa-check"></i><b>1.7.3</b> Data structures</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="r-foundations.html"><a href="r-foundations.html#assignment"><i class="fa fa-check"></i><b>1.8</b> Assignment</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="r-foundations.html"><a href="r-foundations.html#example-3"><i class="fa fa-check"></i><b>1.8.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="r-foundations.html"><a href="r-foundations.html#vectors"><i class="fa fa-check"></i><b>1.9</b> Vectors</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="r-foundations.html"><a href="r-foundations.html#creation"><i class="fa fa-check"></i><b>1.9.1</b> Creation</a></li>
<li class="chapter" data-level="1.9.2" data-path="r-foundations.html"><a href="r-foundations.html#creating-patterned-vectors"><i class="fa fa-check"></i><b>1.9.2</b> Creating patterned vectors</a></li>
<li class="chapter" data-level="1.9.3" data-path="r-foundations.html"><a href="r-foundations.html#example-4"><i class="fa fa-check"></i><b>1.9.3</b> Example</a></li>
<li class="chapter" data-level="1.9.4" data-path="r-foundations.html"><a href="r-foundations.html#example-5"><i class="fa fa-check"></i><b>1.9.4</b> Example</a></li>
<li class="chapter" data-level="1.9.5" data-path="r-foundations.html"><a href="r-foundations.html#categorical-vectors"><i class="fa fa-check"></i><b>1.9.5</b> Categorical vectors</a></li>
<li class="chapter" data-level="1.9.6" data-path="r-foundations.html"><a href="r-foundations.html#example-6"><i class="fa fa-check"></i><b>1.9.6</b> Example</a></li>
<li class="chapter" data-level="1.9.7" data-path="r-foundations.html"><a href="r-foundations.html#extracting-parts-of-a-vector"><i class="fa fa-check"></i><b>1.9.7</b> Extracting parts of a vector</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="r-foundations.html"><a href="r-foundations.html#helpful-functions"><i class="fa fa-check"></i><b>1.10</b> Helpful functions</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="r-foundations.html"><a href="r-foundations.html#general-functions"><i class="fa fa-check"></i><b>1.10.1</b> General functions</a></li>
<li class="chapter" data-level="1.10.2" data-path="r-foundations.html"><a href="r-foundations.html#example-7"><i class="fa fa-check"></i><b>1.10.2</b> Example</a></li>
<li class="chapter" data-level="1.10.3" data-path="r-foundations.html"><a href="r-foundations.html#functions-related-to-statistical-distributions"><i class="fa fa-check"></i><b>1.10.3</b> Functions related to statistical distributions</a></li>
<li class="chapter" data-level="1.10.4" data-path="r-foundations.html"><a href="r-foundations.html#example-8"><i class="fa fa-check"></i><b>1.10.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="r-foundations.html"><a href="r-foundations.html#data-frames"><i class="fa fa-check"></i><b>1.11</b> Data Frames</a>
<ul>
<li class="chapter" data-level="1.11.1" data-path="r-foundations.html"><a href="r-foundations.html#creation-1"><i class="fa fa-check"></i><b>1.11.1</b> Creation</a></li>
<li class="chapter" data-level="1.11.2" data-path="r-foundations.html"><a href="r-foundations.html#extracting-parts-of-a-data-frame"><i class="fa fa-check"></i><b>1.11.2</b> Extracting parts of a data frame</a></li>
<li class="chapter" data-level="1.11.3" data-path="r-foundations.html"><a href="r-foundations.html#example-9"><i class="fa fa-check"></i><b>1.11.3</b> Example</a></li>
<li class="chapter" data-level="1.11.4" data-path="r-foundations.html"><a href="r-foundations.html#importing-data"><i class="fa fa-check"></i><b>1.11.4</b> Importing Data</a></li>
</ul></li>
<li class="chapter" data-level="1.12" data-path="r-foundations.html"><a href="r-foundations.html#logical-statements"><i class="fa fa-check"></i><b>1.12</b> Logical statements</a>
<ul>
<li class="chapter" data-level="1.12.1" data-path="r-foundations.html"><a href="r-foundations.html#basic-comparisons"><i class="fa fa-check"></i><b>1.12.1</b> Basic comparisons</a></li>
<li class="chapter" data-level="1.12.2" data-path="r-foundations.html"><a href="r-foundations.html#example-10"><i class="fa fa-check"></i><b>1.12.2</b> Example</a></li>
<li class="chapter" data-level="1.12.3" data-path="r-foundations.html"><a href="r-foundations.html#and-and-or-statements"><i class="fa fa-check"></i><b>1.12.3</b> And and Or statements</a></li>
<li class="chapter" data-level="1.12.4" data-path="r-foundations.html"><a href="r-foundations.html#example-11"><i class="fa fa-check"></i><b>1.12.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="1.13" data-path="r-foundations.html"><a href="r-foundations.html#subsetting-with-logical-statements"><i class="fa fa-check"></i><b>1.13</b> Subsetting with logical statements</a>
<ul>
<li class="chapter" data-level="1.13.1" data-path="r-foundations.html"><a href="r-foundations.html#example-12"><i class="fa fa-check"></i><b>1.13.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="1.14" data-path="r-foundations.html"><a href="r-foundations.html#ecosystem-debate"><i class="fa fa-check"></i><b>1.14</b> Ecosystem debate</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-exploration.html"><a href="data-exploration.html"><i class="fa fa-check"></i><b>2</b> Data exploration</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-exploration.html"><a href="data-exploration.html#data-analysis-process"><i class="fa fa-check"></i><b>2.1</b> Data analysis process</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="data-exploration.html"><a href="data-exploration.html#problem-formulation"><i class="fa fa-check"></i><b>2.1.1</b> Problem Formulation</a></li>
<li class="chapter" data-level="2.1.2" data-path="data-exploration.html"><a href="data-exploration.html#data-collection"><i class="fa fa-check"></i><b>2.1.2</b> Data collection</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-exploration.html"><a href="data-exploration.html#data-exploration-1"><i class="fa fa-check"></i><b>2.2</b> Data exploration</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="data-exploration.html"><a href="data-exploration.html#numerical-summaries-of-data"><i class="fa fa-check"></i><b>2.2.1</b> Numerical summaries of data</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-exploration.html"><a href="data-exploration.html#visual-summaries-of-data"><i class="fa fa-check"></i><b>2.2.2</b> Visual summaries of data</a></li>
<li class="chapter" data-level="2.2.3" data-path="data-exploration.html"><a href="data-exploration.html#what-to-look-for"><i class="fa fa-check"></i><b>2.2.3</b> What to look for</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-exploration.html"><a href="data-exploration.html#kidney-example"><i class="fa fa-check"></i><b>2.3</b> Kidney Example</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="data-exploration.html"><a href="data-exploration.html#numerically-summarizing-the-data"><i class="fa fa-check"></i><b>2.3.1</b> Numerically summarizing the data</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-exploration.html"><a href="data-exploration.html#cleaning-the-data"><i class="fa fa-check"></i><b>2.3.2</b> Cleaning the data</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="data-exploration.html"><a href="data-exploration.html#visualizing-data-with-base-graphics"><i class="fa fa-check"></i><b>2.4</b> Visualizing data with <strong>base</strong> graphics</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="data-exploration.html"><a href="data-exploration.html#histograms"><i class="fa fa-check"></i><b>2.4.1</b> Histograms</a></li>
<li class="chapter" data-level="2.4.2" data-path="data-exploration.html"><a href="data-exploration.html#density-plots"><i class="fa fa-check"></i><b>2.4.2</b> Density plots</a></li>
<li class="chapter" data-level="2.4.3" data-path="data-exploration.html"><a href="data-exploration.html#index-plots"><i class="fa fa-check"></i><b>2.4.3</b> Index plots</a></li>
<li class="chapter" data-level="2.4.4" data-path="data-exploration.html"><a href="data-exploration.html#bivariate-scatter-plots"><i class="fa fa-check"></i><b>2.4.4</b> Bivariate scatter plots</a></li>
<li class="chapter" data-level="2.4.5" data-path="data-exploration.html"><a href="data-exploration.html#bivariate-boxplots"><i class="fa fa-check"></i><b>2.4.5</b> Bivariate boxplots</a></li>
<li class="chapter" data-level="2.4.6" data-path="data-exploration.html"><a href="data-exploration.html#multiple-plots-in-one-figure"><i class="fa fa-check"></i><b>2.4.6</b> Multiple plots in one figure</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="data-exploration.html"><a href="data-exploration.html#visualizing-data-with-ggplot2"><i class="fa fa-check"></i><b>2.5</b> Visualizing data with <strong>ggplot2</strong></a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="data-exploration.html"><a href="data-exploration.html#a-ggplot2-histogram"><i class="fa fa-check"></i><b>2.5.1</b> A <strong>ggplot2</strong> histogram</a></li>
<li class="chapter" data-level="2.5.2" data-path="data-exploration.html"><a href="data-exploration.html#a-ggplot2-density-plot"><i class="fa fa-check"></i><b>2.5.2</b> A <strong>ggplot2</strong> density plot</a></li>
<li class="chapter" data-level="2.5.3" data-path="data-exploration.html"><a href="data-exploration.html#a-ggplot2-scatter-plot"><i class="fa fa-check"></i><b>2.5.3</b> A <strong>ggplot2</strong> scatter plot</a></li>
<li class="chapter" data-level="2.5.4" data-path="data-exploration.html"><a href="data-exploration.html#scaling-ggplot2-plots"><i class="fa fa-check"></i><b>2.5.4</b> Scaling <strong>ggplot2</strong> plots</a></li>
<li class="chapter" data-level="2.5.5" data-path="data-exploration.html"><a href="data-exploration.html#facetting-in-ggplot2"><i class="fa fa-check"></i><b>2.5.5</b> Facetting in <code>ggplot2</code></a></li>
<li class="chapter" data-level="2.5.6" data-path="data-exploration.html"><a href="data-exploration.html#summary-of-ggplot2"><i class="fa fa-check"></i><b>2.5.6</b> Summary of <strong>ggplot2</strong></a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="data-exploration.html"><a href="data-exploration.html#summary-of-data-exploration"><i class="fa fa-check"></i><b>2.6</b> Summary of data exploration</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html"><i class="fa fa-check"></i><b>3</b> Review of probability, random variables, and random vectors</a>
<ul>
<li class="chapter" data-level="3.1" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#probability-basics"><i class="fa fa-check"></i><b>3.1</b> Probability Basics</a></li>
<li class="chapter" data-level="3.2" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#random-variables"><i class="fa fa-check"></i><b>3.2</b> Random Variables</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#discrete-random-variables"><i class="fa fa-check"></i><b>3.2.1</b> Discrete random variables</a></li>
<li class="chapter" data-level="3.2.2" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#continuous-random-variables"><i class="fa fa-check"></i><b>3.2.2</b> Continuous random variables</a></li>
<li class="chapter" data-level="3.2.3" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#useful-facts-for-transformation-of-random-variables"><i class="fa fa-check"></i><b>3.2.3</b> Useful facts for transformation of random variables</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#multivariate-distributions"><i class="fa fa-check"></i><b>3.3</b> Multivariate distributions</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#basic-properties"><i class="fa fa-check"></i><b>3.3.1</b> Basic properties</a></li>
<li class="chapter" data-level="3.3.2" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#marginal-distributions"><i class="fa fa-check"></i><b>3.3.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="3.3.3" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#independence-of-random-variables"><i class="fa fa-check"></i><b>3.3.3</b> Independence of random variables</a></li>
<li class="chapter" data-level="3.3.4" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#conditional-distributions"><i class="fa fa-check"></i><b>3.3.4</b> Conditional distributions</a></li>
<li class="chapter" data-level="3.3.5" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#covariance"><i class="fa fa-check"></i><b>3.3.5</b> Covariance</a></li>
<li class="chapter" data-level="3.3.6" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#useful-facts-for-transformations-of-multiple-random-variables"><i class="fa fa-check"></i><b>3.3.6</b> Useful facts for transformations of multiple random variables</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#random-vectors"><i class="fa fa-check"></i><b>3.4</b> Random vectors</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#definition"><i class="fa fa-check"></i><b>3.4.1</b> Definition</a></li>
<li class="chapter" data-level="3.4.2" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#mean-variance-and-covariance"><i class="fa fa-check"></i><b>3.4.2</b> Mean, variance, and covariance</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#properties-of-transformations-of-random-vectors"><i class="fa fa-check"></i><b>3.5</b> Properties of transformations of random vectors</a></li>
<li class="chapter" data-level="3.6" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#multivariate-normal-gaussian-distribution"><i class="fa fa-check"></i><b>3.6</b> Multivariate normal (Gaussian) distribution</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#definition-1"><i class="fa fa-check"></i><b>3.6.1</b> Definition</a></li>
<li class="chapter" data-level="3.6.2" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#useful-facts"><i class="fa fa-check"></i><b>3.6.2</b> Useful facts</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#example-1-1"><i class="fa fa-check"></i><b>3.7</b> Example 1</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#bernoulli-distribution"><i class="fa fa-check"></i><b>3.7.1</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="3.7.2" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#binomial-distribution"><i class="fa fa-check"></i><b>3.7.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.7.3" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#poisson-distribution"><i class="fa fa-check"></i><b>3.7.3</b> Poisson Distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#example-2-1"><i class="fa fa-check"></i><b>3.8</b> Example 2</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#problem-1"><i class="fa fa-check"></i><b>3.8.1</b> Problem 1</a></li>
<li class="chapter" data-level="3.8.2" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#problem-2"><i class="fa fa-check"></i><b>3.8.2</b> Problem 2</a></li>
<li class="chapter" data-level="3.8.3" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#problem-3"><i class="fa fa-check"></i><b>3.8.3</b> Problem 3</a></li>
<li class="chapter" data-level="3.8.4" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#problem-4"><i class="fa fa-check"></i><b>3.8.4</b> Problem 4</a></li>
<li class="chapter" data-level="3.8.5" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#problem-5"><i class="fa fa-check"></i><b>3.8.5</b> Problem 5</a></li>
<li class="chapter" data-level="3.8.6" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#problem-6"><i class="fa fa-check"></i><b>3.8.6</b> Problem 6</a></li>
<li class="chapter" data-level="3.8.7" data-path="review-of-probability-random-variables-and-random-vectors.html"><a href="review-of-probability-random-variables-and-random-vectors.html#problem-7"><i class="fa fa-check"></i><b>3.8.7</b> Problem 7</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html"><i class="fa fa-check"></i><b>4</b> Useful matrix facts</a>
<ul>
<li class="chapter" data-level="4.1" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#notation"><i class="fa fa-check"></i><b>4.1</b> Notation</a></li>
<li class="chapter" data-level="4.2" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#basic-mathematical-properties"><i class="fa fa-check"></i><b>4.2</b> Basic mathematical properties</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#addition-and-subtraction"><i class="fa fa-check"></i><b>4.2.1</b> Addition and subtraction</a></li>
<li class="chapter" data-level="4.2.2" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#scalar-multiplication"><i class="fa fa-check"></i><b>4.2.2</b> Scalar multiplication</a></li>
<li class="chapter" data-level="4.2.3" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#matrix-multiplication"><i class="fa fa-check"></i><b>4.2.3</b> Matrix multiplication</a></li>
<li class="chapter" data-level="4.2.4" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#associative-property"><i class="fa fa-check"></i><b>4.2.4</b> Associative property</a></li>
<li class="chapter" data-level="4.2.5" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#distributive-property"><i class="fa fa-check"></i><b>4.2.5</b> Distributive property</a></li>
<li class="chapter" data-level="4.2.6" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#no-commutative-property"><i class="fa fa-check"></i><b>4.2.6</b> No commutative property</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#transpose-and-related-properties"><i class="fa fa-check"></i><b>4.3</b> Transpose and related properties</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#definition-2"><i class="fa fa-check"></i><b>4.3.1</b> Definition</a></li>
<li class="chapter" data-level="4.3.2" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#transpose-and-mathematical-operations"><i class="fa fa-check"></i><b>4.3.2</b> Transpose and mathematical operations</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#special-matrices"><i class="fa fa-check"></i><b>4.4</b> Special matrices</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#square-matrices"><i class="fa fa-check"></i><b>4.4.1</b> Square matrices</a></li>
<li class="chapter" data-level="4.4.2" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#identity-matrix"><i class="fa fa-check"></i><b>4.4.2</b> Identity matrix</a></li>
<li class="chapter" data-level="4.4.3" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#symmetric"><i class="fa fa-check"></i><b>4.4.3</b> Symmetric</a></li>
<li class="chapter" data-level="4.4.4" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#idempotent"><i class="fa fa-check"></i><b>4.4.4</b> Idempotent</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#matrix-inverse"><i class="fa fa-check"></i><b>4.5</b> Matrix inverse</a></li>
<li class="chapter" data-level="4.6" data-path="useful-matrix-facts.html"><a href="useful-matrix-facts.html#matrix-derivatives"><i class="fa fa-check"></i><b>4.6</b> Matrix derivatives</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html"><i class="fa fa-check"></i><b>5</b> Defining and fitting a linear model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#background-and-terminology"><i class="fa fa-check"></i><b>5.1</b> Background and terminology</a></li>
<li class="chapter" data-level="5.2" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#goals-of-regression"><i class="fa fa-check"></i><b>5.2</b> Goals of regression</a></li>
<li class="chapter" data-level="5.3" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#definition-of-a-linear-model"><i class="fa fa-check"></i><b>5.3</b> Definition of a linear model</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#basic-construction-and-relationships"><i class="fa fa-check"></i><b>5.3.1</b> Basic construction and relationships</a></li>
<li class="chapter" data-level="5.3.2" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#as-a-system-of-equations"><i class="fa fa-check"></i><b>5.3.2</b> As a system of equations</a></li>
<li class="chapter" data-level="5.3.3" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#using-matrix-notation"><i class="fa fa-check"></i><b>5.3.3</b> Using matrix notation</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#summarizing-the-components-of-a-linear-model"><i class="fa fa-check"></i><b>5.4</b> Summarizing the components of a linear model</a></li>
<li class="chapter" data-level="5.5" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#types-of-regression-models"><i class="fa fa-check"></i><b>5.5</b> Types of regression models</a></li>
<li class="chapter" data-level="5.6" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#standard-linear-model-assumptions-and-implications"><i class="fa fa-check"></i><b>5.6</b> Standard linear model assumptions and implications</a></li>
<li class="chapter" data-level="5.7" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#mathematical-interpretation-of-coefficients"><i class="fa fa-check"></i><b>5.7</b> Mathematical interpretation of coefficients</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#coefficient-interpretation-in-simple-linear-regression"><i class="fa fa-check"></i><b>5.7.1</b> Coefficient interpretation in simple linear regression</a></li>
<li class="chapter" data-level="5.7.2" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#coefficient-interpretation-in-multiple-linear-regression"><i class="fa fa-check"></i><b>5.7.2</b> Coefficient interpretation in multiple linear regression</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="defining-and-fitting-a-linear-model.html"><a href="defining-and-fitting-a-linear-model.html#exercises"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html"><i class="fa fa-check"></i><b>6</b> Linear model estimation</a>
<ul>
<li class="chapter" data-level="6.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#a-simple-motivating-example"><i class="fa fa-check"></i><b>6.1</b> A simple motivating example</a></li>
<li class="chapter" data-level="6.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#defining-a-linear-model"><i class="fa fa-check"></i><b>6.2</b> Defining a linear model</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss-necessary-components"><i class="fa fa-check"></i><b>6.2.1</b> Necessary components and notation</a></li>
<li class="chapter" data-level="6.2.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#standard-definition-of-linear-model"><i class="fa fa-check"></i><b>6.2.2</b> Standard definition of linear model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#estimation-of-the-simple-linear-regression-model"><i class="fa fa-check"></i><b>6.3</b> Estimation of the simple linear regression model</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss:fv-resid-rss"><i class="fa fa-check"></i><b>6.3.1</b> Fitted values, residuals, and RSS</a></li>
<li class="chapter" data-level="6.3.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ols-estimators-of-the-simple-linear-regression-parameters"><i class="fa fa-check"></i><b>6.3.2</b> OLS estimators of the simple linear regression parameters</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s:penguins-slr"><i class="fa fa-check"></i><b>6.4</b> Penguins simple linear regression example</a></li>
<li class="chapter" data-level="6.5" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#estimation-of-the-multiple-linear-regression-coefficients"><i class="fa fa-check"></i><b>6.5</b> Estimation of the multiple linear regression coefficients)</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#using-matrix-notation-to-represent-a-linear-model"><i class="fa fa-check"></i><b>6.5.1</b> Using matrix notation to represent a linear model</a></li>
<li class="chapter" data-level="6.5.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss:fv-resid-rss-mlr"><i class="fa fa-check"></i><b>6.5.2</b> Residuals, fitted values, and RSS for multiple linear regression</a></li>
<li class="chapter" data-level="6.5.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ols-estimator-of-the-linear-model-parameters"><i class="fa fa-check"></i><b>6.5.3</b> OLS estimator of the linear model parameters</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s:penguins-mlr"><i class="fa fa-check"></i><b>6.6</b> Penguins multiple linear regression example</a></li>
<li class="chapter" data-level="6.7" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#categorical-predictors"><i class="fa fa-check"></i><b>6.7</b> Categorical predictors</a></li>
<li class="chapter" data-level="6.8" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s:penguins-mlr"><i class="fa fa-check"></i><b>6.8</b> Penguins multiple linear regression example with categorical predictor</a></li>
<li class="chapter" data-level="6.9" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#evaluating-model-fit"><i class="fa fa-check"></i><b>6.9</b> Evaluating model fit</a></li>
<li class="chapter" data-level="6.10" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#summary-of-notation"><i class="fa fa-check"></i><b>6.10</b> Summary of notation</a></li>
<li class="chapter" data-level="6.11" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#summary-of-functions-used-in-this-chapter"><i class="fa fa-check"></i><b>6.11</b> Summary of functions used in this chapter</a></li>
<li class="chapter" data-level="6.12" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#summarizing-the-components-of-a-linear-model-1"><i class="fa fa-check"></i><b>6.12</b> Summarizing the components of a linear model</a></li>
<li class="chapter" data-level="6.13" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#going-deeper"><i class="fa fa-check"></i><b>6.13</b> Going Deeper</a>
<ul>
<li class="chapter" data-level="6.13.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#manually-estimating-the-simple-linear-regression-coefficients"><i class="fa fa-check"></i><b>6.13.1</b> Manually estimating the simple linear regression coefficients</a></li>
<li class="chapter" data-level="6.13.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#manually-estimating-the-multiple-linear-regression-coefficients"><i class="fa fa-check"></i><b>6.13.2</b> Manually estimating the multiple linear regression coefficients</a></li>
<li class="chapter" data-level="6.13.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#parameter-estimation-and-matrix-decompositions"><i class="fa fa-check"></i><b>6.13.3</b> Parameter estimation and matrix decompositions</a></li>
<li class="chapter" data-level="6.13.4" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#updating-a-model"><i class="fa fa-check"></i><b>6.13.4</b> Updating a model</a></li>
<li class="chapter" data-level="6.13.5" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#more-discussion-of-formula-for-model-building"><i class="fa fa-check"></i><b>6.13.5</b> More discussion of <code>formula</code> for model-building</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="parameter-estimation-for-linear-models.html"><a href="parameter-estimation-for-linear-models.html"><i class="fa fa-check"></i><b>7</b> Parameter estimation for linear models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="parameter-estimation-for-linear-models.html"><a href="parameter-estimation-for-linear-models.html#ols-estimation-of-the-simple-linear-regression-model"><i class="fa fa-check"></i><b>7.1</b> OLS estimation of the simple linear regression model</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="parameter-estimation-for-linear-models.html"><a href="parameter-estimation-for-linear-models.html#visualizing-the-rss-as-a-function-of-the-estimated-coefficients"><i class="fa fa-check"></i><b>7.1.1</b> Visualizing the RSS as a function of the estimated coefficients</a></li>
<li class="chapter" data-level="7.1.2" data-path="parameter-estimation-for-linear-models.html"><a href="parameter-estimation-for-linear-models.html#ols-estimators-of-the-simple-linear-regression-parameters-1"><i class="fa fa-check"></i><b>7.1.2</b> OLS estimators of the simple linear regression parameters</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="parameter-estimation-for-linear-models.html"><a href="parameter-estimation-for-linear-models.html#penguins-simple-linear-regression-example"><i class="fa fa-check"></i><b>7.2</b> Penguins simple linear regression example</a></li>
<li class="chapter" data-level="7.3" data-path="parameter-estimation-for-linear-models.html"><a href="parameter-estimation-for-linear-models.html#fitting-a-linear-model-using-r"><i class="fa fa-check"></i><b>7.3</b> Fitting a linear model using R</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="parameter-estimation-for-linear-models.html"><a href="parameter-estimation-for-linear-models.html#derivation-of-ols-simple-linear-regression-estimators"><i class="fa fa-check"></i><b>7.3.1</b> Derivation of OLS simple linear regression estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="interpreting-a-fitted-linear-model.html"><a href="interpreting-a-fitted-linear-model.html"><i class="fa fa-check"></i><b>8</b> Interpreting a fitted linear model</a>
<ul>
<li class="chapter" data-level="8.1" data-path="interpreting-a-fitted-linear-model.html"><a href="interpreting-a-fitted-linear-model.html#orthogonality"><i class="fa fa-check"></i><b>8.1</b> Orthogonality</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="categorical-predictors-1.html"><a href="categorical-predictors-1.html"><i class="fa fa-check"></i><b>9</b> Categorical predictors</a>
<ul>
<li class="chapter" data-level="9.1" data-path="categorical-predictors-1.html"><a href="categorical-predictors-1.html#indicatordummy-variables"><i class="fa fa-check"></i><b>9.1</b> Indicator/dummy variables</a></li>
<li class="chapter" data-level="9.2" data-path="categorical-predictors-1.html"><a href="categorical-predictors-1.html#common-of-linear-models-with-categorical-predictors"><i class="fa fa-check"></i><b>9.2</b> Common of linear models with categorical predictors</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="categorical-predictors-1.html"><a href="categorical-predictors-1.html#one-way-anova"><i class="fa fa-check"></i><b>9.2.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="9.2.2" data-path="categorical-predictors-1.html"><a href="categorical-predictors-1.html#main-effects-models"><i class="fa fa-check"></i><b>9.2.2</b> Main effects models</a></li>
<li class="chapter" data-level="9.2.3" data-path="categorical-predictors-1.html"><a href="categorical-predictors-1.html#interaction-models"><i class="fa fa-check"></i><b>9.2.3</b> Interaction models</a></li>
<li class="chapter" data-level="9.2.4" data-path="categorical-predictors-1.html"><a href="categorical-predictors-1.html#extensions"><i class="fa fa-check"></i><b>9.2.4</b> Extensions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="assessing-and-addressing-collinearity.html"><a href="assessing-and-addressing-collinearity.html"><i class="fa fa-check"></i><b>10</b> Assessing and addressing collinearity</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="11" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html"><i class="fa fa-check"></i><b>11</b> Defining and fitting a linear model</a>
<ul>
<li class="chapter" data-level="11.1" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#background-and-terminology-1"><i class="fa fa-check"></i><b>11.1</b> Background and terminology</a></li>
<li class="chapter" data-level="11.2" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#goals-of-regression-1"><i class="fa fa-check"></i><b>11.2</b> Goals of regression</a></li>
<li class="chapter" data-level="11.3" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#definition-of-a-linear-model-1"><i class="fa fa-check"></i><b>11.3</b> Definition of a linear model</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#basic-construction-and-relationships-1"><i class="fa fa-check"></i><b>11.3.1</b> Basic construction and relationships</a></li>
<li class="chapter" data-level="11.3.2" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#as-a-system-of-equations-1"><i class="fa fa-check"></i><b>11.3.2</b> As a system of equations</a></li>
<li class="chapter" data-level="11.3.3" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#using-matrix-notation-1"><i class="fa fa-check"></i><b>11.3.3</b> Using matrix notation</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#summarizing-the-components-of-a-linear-model-2"><i class="fa fa-check"></i><b>11.4</b> Summarizing the components of a linear model</a></li>
<li class="chapter" data-level="11.5" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#types-of-regression-models-1"><i class="fa fa-check"></i><b>11.5</b> Types of regression models</a></li>
<li class="chapter" data-level="11.6" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#standard-linear-model-assumptions-and-implications-1"><i class="fa fa-check"></i><b>11.6</b> Standard linear model assumptions and implications</a></li>
<li class="chapter" data-level="11.7" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#mathematical-interpretation-of-coefficients-1"><i class="fa fa-check"></i><b>11.7</b> Mathematical interpretation of coefficients</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#coefficient-interpretation-in-simple-linear-regression-1"><i class="fa fa-check"></i><b>11.7.1</b> Coefficient interpretation in simple linear regression</a></li>
<li class="chapter" data-level="11.7.2" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#coefficient-interpretation-in-multiple-linear-regression-1"><i class="fa fa-check"></i><b>11.7.2</b> Coefficient interpretation in multiple linear regression</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="defining-and-fitting-a-linear-model-1.html"><a href="defining-and-fitting-a-linear-model-1.html#exercises-1"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="linear-model-inference.html"><a href="linear-model-inference.html"><i class="fa fa-check"></i><b>12</b> Linear model inference</a></li>
<li class="chapter" data-level="13" data-path="assumptions-stated-and-prioritized.html"><a href="assumptions-stated-and-prioritized.html"><i class="fa fa-check"></i><b>13</b> Assumptions Stated and Prioritized</a>
<ul>
<li class="chapter" data-level="13.1" data-path="assumptions-stated-and-prioritized.html"><a href="assumptions-stated-and-prioritized.html#standard-assumptions-concisely-stated"><i class="fa fa-check"></i><b>13.1</b> Standard assumptions concisely stated</a></li>
<li class="chapter" data-level="13.2" data-path="assumptions-stated-and-prioritized.html"><a href="assumptions-stated-and-prioritized.html#standard-assumptions-prioritized"><i class="fa fa-check"></i><b>13.2</b> Standard assumptions prioritized</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Joshua French</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-model-estimation" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> Linear model estimation</h1>
<div id="a-simple-motivating-example" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> A simple motivating example</h2>
<p>Suppose you observe data related to the heights of 5 mothers and their
adult daughters. The observed heights (measured in inches) are provided
in Table <a href="linear-model-estimation.html#tab:mdheights">6.1</a>.</p>
<table>
<caption><span id="tab:mdheights">Table 6.1: </span>Heights of mothers and their adult daughters (in).</caption>
<thead>
<tr class="header">
<th align="right">observation</th>
<th align="right">mother’s height (in)</th>
<th align="right">daughter’s height (in)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">57.5</td>
<td align="right">61.5</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">60.5</td>
<td align="right">63.5</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">63.5</td>
<td align="right">63.5</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">66.5</td>
<td align="right">66.5</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">69.5</td>
<td align="right">66.5</td>
</tr>
</tbody>
</table>
<p>The 5 pairs of observed data are denoted
<span class="math display">\[(x_1, Y_1), (x_2, Y_2), \ldots, (x_5, Y_5),\]</span> with <span class="math inline">\((x_i, Y_i)\)</span>
denoting the data for observation <span class="math inline">\(i\)</span>. <span class="math inline">\(x_i\)</span> denotes the mother’s height
for observation <span class="math inline">\(i\)</span> and <span class="math inline">\(Y_i\)</span> denotes the daughter’s height for
observation <span class="math inline">\(i\)</span>. In this data set, e.g., <span class="math inline">\(x_3 = 63.5\)</span> and <span class="math inline">\(Y_5= 66.5\)</span>.</p>
<p>Figure <a href="linear-model-estimation.html#fig:mdheights-plot">6.1</a> displays a scatter plot of height data
provided in Table <a href="linear-model-estimation.html#tab:mdheights">6.1</a>. The relationship between the
points is approximately a straight line. Thus, we will model the typical
(mean) relationship between the height of mothers and their adult
daughters as a straight line.</p>
<div class="figure"><span id="fig:mdheights-plot"></span>
<img src="Data-Analysis-with-Linear-Regression_files/figure-html/mdheights-plot-1.png" alt="A scatter plot displaying pairs of heights for a mother and her adult daughter." width="672" />
<p class="caption">
Figure 6.1: A scatter plot displaying pairs of heights for a mother and her adult daughter.
</p>
</div>
<p>The <span class="math inline">\(x_1,x_2,\ldots,x_5\)</span> are observed values of a random variable <span class="math inline">\(X\)</span>,
while <span class="math inline">\(Y_1, Y_2, \ldots, Y_5\)</span> are observed values of a random variable
<span class="math inline">\(Y\)</span>. Thus, <span class="math inline">\(X\)</span> denotes the height a mother and <span class="math inline">\(Y\)</span> denotes the height of
(one of) their adult daughter(s). We want to model variable <span class="math inline">\(Y\)</span> using
variable <span class="math inline">\(X\)</span>. The variable we are trying to model is known as the
<strong>response variable</strong>. The variables we use to model the response are
known as <strong>regressor variables</strong>. Response variables are also known as
<strong>outcome</strong>, <strong>output</strong>, or <strong>dependent</strong> variables. Regressor variables
are also known as <strong>explanatory</strong>, <strong>predictor</strong>, <strong>input</strong>,
<strong>dependent</strong>, or <strong>feature</strong> variables.</p>
<p>A regression model describes the typical relationship between the
response variable <span class="math inline">\(Y\)</span> as a function of the regressor variable <span class="math inline">\(X\)</span>. More
formally, the <strong>regression model</strong> for <span class="math inline">\(Y\)</span> as a function of <span class="math inline">\(X\)</span>, denoted
<span class="math inline">\(E(Y|X)\)</span> is the expected value of <span class="math inline">\(Y\)</span> conditional on the regressor <span class="math inline">\(X\)</span>.
The regression model specifically refers to the expected relationship
between the response and regressors.</p>
<p>A <strong>simple linear regression model</strong> assumes the regression model
between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> is a straight line using the equation
<span class="math display">\[E(Y\mid X)=\beta_0 + \beta_1 X.\]</span> <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are the
intercept and slope of our regression functions. In general, <span class="math inline">\(\beta_0\)</span>
and <span class="math inline">\(\beta_1\)</span> are known as <strong>regression coefficients</strong> and are model
parameters that we estimate from our data.</p>
<p>The estimated regression model is denoted by
<span class="math display">\[\hat{E}(Y|X)=\hat{\beta}_0 + \hat{\beta}_1 X,\]</span> where <span class="math inline">\(\hat{\beta}_0\)</span>
and <span class="math inline">\(\hat{\beta}_1\)</span> are values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> that we
estimate from the data. A <span class="math inline">\(\hat{}\)</span> above a term indicates it is an
estimate. We will refer to <span class="math inline">\(\hat{E}(Y|X)\)</span> as the <strong>fitted model</strong> or
<strong>estimated regression model</strong>.</p>
<p>How do we determine the “best fitting” model? Consider Figure
<a href="linear-model-estimation.html#fig:three-fitted-lines">6.2</a>, in which 2 potential “best fitting”
models are drawn on the scatter plot of the height data. Which one is
best?</p>
<div class="figure"><span id="fig:three-fitted-lines"></span>
<img src="Data-Analysis-with-Linear-Regression_files/figure-html/three-fitted-lines-1.png" alt="Comparison of three potential fitted models to some observed data. The fitted models are shown in grey." width="672" />
<p class="caption">
Figure 6.2: Comparison of three potential fitted models to some observed data. The fitted models are shown in grey.
</p>
</div>
<p>The rest of this chapter focuses on defining and estimating the
parameters of a <em>linear</em> regression model.</p>
</div>
<div id="defining-a-linear-model" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Defining a linear model</h2>
<div id="ss-necessary-components" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Necessary components and notation</h3>
<p>We begin by defining notation for the components of a linear model and
some of their important properties. We repeat some of the previous
discussion for clarity.</p>
<ul>
<li><p><span class="math inline">\(Y\)</span> denotes the response variable.</p>
<ul>
<li>The response variable is treated as a random variable.</li>
<li>We will observe realizations of this random variable for each
observation in our data set.</li>
</ul></li>
<li><p><span class="math inline">\(X\)</span> denotes a single regressor variable. <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, ,
<span class="math inline">\(X_{p-1}\)</span> denote distinct regressor variables if we are performing
multiple regression.</p>
<ul>
<li>The regressor variables are treated as non-random variables.</li>
<li>The observed values of the regressor variables are treated as
fixed, known values.</li>
</ul></li>
<li><p><span class="math inline">\(\mathbb{X}=\{X_1,\ldots,X_{p-1}\}\)</span> denotes the collection of all
regressors under consideration, though this notation is really only
needed in the context of multiple regression.</p></li>
<li><p><span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(\beta_{p-1}\)</span> denote <strong>regression
coefficients</strong>.</p>
<ul>
<li>Regression coefficients are statistical parameters that we will
estimate from our data.</li>
<li>The regression coefficients are treated as fixed (non-random)
but unknown values.</li>
<li>Regression coefficients are not observable.</li>
</ul></li>
<li><p><span class="math inline">\(\epsilon\)</span> denotes model <strong>error</strong>.</p>
<ul>
<li>The model error is more accurately described as random variation
of each observation from the regression model
<span class="math inline">\(E(\epsilon\mid\mathbb{X})\)</span>.</li>
<li>The error is treated as a random variable.</li>
<li>The error is assumed to have mean 0 for all values of the
regressors, i.e., <span class="math inline">\(E(\epsilon\mid\mathbb{X}) = 0\)</span>.</li>
<li>The variance of the errors is assumed to be a constant value for
all values of the regressors, i.e.,
<span class="math inline">\(\mathrm{var}(\epsilon\mid\mathbb{X})=\sigma^2\)</span>.</li>
<li>The error is never observable (except in the context of a
simulation study where the experimenter literally defines the
true model).</li>
</ul></li>
</ul>
</div>
<div id="standard-definition-of-linear-model" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Standard definition of linear model</h3>
<p>A <strong>linear model</strong> for <span class="math inline">\(Y\)</span> is defined by the equation <span class="math display" id="eq:lmdef">\[\begin{align}
Y &amp;= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_{p-1}
X_{p-1} + \epsilon \\
&amp;= E(Y \mid \mathbb{X}) + \epsilon \tag{6.1}
\end{align}\]</span></p>
<p>We write the model using the form in Equation <a href="linear-model-estimation.html#eq:lmdef">(6.1)</a> to
emphasize the fact <strong>the response value equals the expected response for
that combination of regressor values plus some error</strong>. It should be
clear from comparing Equation <a href="linear-model-estimation.html#eq:lmdef">(6.1)</a> with the previous line
that
<span class="math display">\[E(Y \mid \mathbb{X}) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_{p-1} X_{p-1},\]</span>
which we will prove later.</p>
<p>More generally, one can say that a regression model is linear if the
mean function can be written as a linear combination of the regression
coefficients and known values created from our regressor variables,
i.e.,
<span class="math display" id="eq:lmdef-cj">\[\begin{equation}
E(Y \mid X_1, X_2, \ldots, X_{p-1}) = \sum_{j=0}^{p-1} c_j \beta_j, \tag{6.2}
\end{equation}\]</span>
where <span class="math inline">\(c_0, c_1, \ldots, c_{p-1}\)</span> are known functions of
the regressor variables, e.g., <span class="math inline">\(c_1 = X_1 X_2 X_3\)</span>, <span class="math inline">\(c_3 = X_2^2\)</span>,
<span class="math inline">\(c_8 = \ln(X_1)/X_2^2\)</span>, etc. Thus, if <span class="math inline">\(g_0,\ldots,g_{p-1}\)</span> are functions
of <span class="math inline">\(\mathbb{X}\)</span>, then we can say that the regression model is linear if
it can be written as
<span class="math display">\[E(Y\mid \mathbb{X}) = \sum_{j=0}^{p-1} g_j(\mathbb{X})\beta_j.\]</span></p>
<p>Some examples of linear regression models:</p>
<ul>
<li><span class="math inline">\(E(Y|X) = \beta_0\)</span>.</li>
<li><span class="math inline">\(E(Y|X) = \beta_0 + +\beta_1 X + \beta_2 X^2\)</span>.</li>
<li><span class="math inline">\(E(Y|X_1, X_2) = \beta_0 + \beta_1 X_1 + \beta_2 X_2\)</span>.</li>
<li><span class="math inline">\(E(Y|X_1, X_2) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2\)</span>.</li>
<li><span class="math inline">\(E(Y|X_1, X_2) = \beta_0 + \beta_1 \ln(X_1) + \beta_2 X_2^{-1}\)</span>.</li>
<li><span class="math inline">\(E(\ln(Y)|X_1, X_2) = \beta_0 + \beta_1 X_1 + \beta_2 X_2\)</span>.</li>
<li><span class="math inline">\(E(Y^{-1}|X_1, X_2) = \beta_0 + \beta_1 X_1 + \beta_2 X_2\)</span>.</li>
</ul>
<p>Some examples of non-linear regression models:</p>
<ul>
<li><span class="math inline">\(E(Y|X) = \beta_0 + e^{\beta_1 X}\)</span>.</li>
<li><span class="math inline">\(E(Y|X) = \beta_0 + \beta_1 X/(\beta_2 + X)\)</span>.</li>
</ul>
<p>The latter regression models are non-linear models because there is no
way to express them using the expression in Equation <a href="linear-model-estimation.html#eq:lmdef-cj">(6.2)</a>.</p>
<p>There are many different methods of parameter estimation in statistics:
method-of-moments, maximum likelihood, Bayesian, etc. The most common
parameter estimation method for linear models is the <strong>least squares
method</strong>, which is commonly called <strong>Ordinary Least Squares (OLS)</strong>
estimation. OLS estimation estimates the regression coefficients with
the values that minimize the residual sum of squares (RSS), which we
will define shortly.</p>
</div>
</div>
<div id="estimation-of-the-simple-linear-regression-model" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Estimation of the simple linear regression model</h2>
<div id="ss:fv-resid-rss" class="section level3" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Fitted values, residuals, and RSS</h3>
<p>Recall that a simple linear regression model is defined by the equation
<span class="math display">\[Y = \beta_0 + \beta_1 X + \epsilon = E(Y|X) + \epsilon\]</span> where
<span class="math display">\[E(Y|X) = \beta_0 + \beta_1 X.\]</span> In a simple linear regression context,
we have <span class="math inline">\(n\)</span> observed responses <span class="math inline">\(Y_1,Y_2,\ldots,Y_n\)</span> and <span class="math inline">\(n\)</span> regressor
values <span class="math inline">\(x_1,x_2,\ldots,x_n\)</span>.</p>
<p>Let <span class="math inline">\(\hat{\beta}_j\)</span> denote the estimated value of <span class="math inline">\(\beta_j\)</span> and
<span class="math inline">\(\hat{E}(Y|X) = \hat{\beta}_0 + \hat{\beta}_1 X\)</span> denote the estimated
regression model.</p>
<p>The <span class="math inline">\(i\)</span>th fitted value is defined as
<span class="math display" id="eq:def-fitted-value-slr">\[\begin{equation}
\hat{Y}_i = \hat{E}(Y|X = x_i) = \hat{\beta}_0 + \hat{\beta}_1 x_i. \tag{6.3}
\end{equation}\]</span>
Thus, the <span class="math inline">\(i\)</span>th fitted value is the estimated mean of <span class="math inline">\(Y\)</span> when the
regressor <span class="math inline">\(X=x_i\)</span>. More specifically, the <span class="math inline">\(i\)</span>th fitted value is the
estimated mean response for the combination of regressor values observed
for the <span class="math inline">\(i\)</span>th observation.</p>
<p>The <span class="math inline">\(i\)</span>th residual is defined as
<span class="math display" id="eq:def-residual-slr">\[\begin{equation}
\hat{\epsilon}_i = Y_i - \hat{Y}_i. \tag{6.4}
\end{equation}\]</span>
The <span class="math inline">\(i\)</span>th residual is the difference between the response and estimated
mean response of observation <span class="math inline">\(i\)</span>.</p>
<p><strong>The RSS of a regression model is the sum of its squared residuals</strong>.</p>
<p>The RSS for a simple linear regression model, as a function of the
estimated regression coefficients <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span>, is defined as
<span class="math display" id="eq:def-rss-slr">\[\begin{equation}
RSS(\hat{\beta}_0, \hat{\beta}_1) = \sum_{i=1}^n \hat{\epsilon}_i^2. \tag{6.5}
\end{equation}\]</span></p>
<p>Using several of objects defined above, there are many equivalent expressions for the RSS. Notably, Equation <a href="linear-model-estimation.html#eq:def-rss-slr">(6.5)</a> can be rewritten using Equations <a href="linear-model-estimation.html#eq:def-residual-slr">(6.4)</a> and <a href="linear-model-estimation.html#eq:def-fitted-value-slr">(6.3)</a> as
<span class="math display">\[\begin{align*}
RSS(\hat{\beta}_0, \hat{\beta}_1) &amp;= \sum_{i=1}^n \hat{\epsilon}_i^2 \\
&amp;= \sum_{i=1}^n (Y_i - \hat{Y}_i)^2 &amp; \\
&amp;= \sum_{i=1}^n (Y_i - \hat{E}(Y|X=x_i))^2 \\
&amp;= \sum_{i=1}^n (Y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i))^2.
\end{align*}\]</span></p>
<p>The <strong>fitted model</strong> is the estimated model that minimizes the RSS, i.e., the fitted model (in the context of simple linear regression) is defined as
<span class="math display" id="eq:def-fitted-model-slr">\[\begin{equation}
\hat{E}(Y|X) = \hat{\beta}_0 + \hat{\beta}_1 X. \tag{6.6}
\end{equation}\]</span>
In a simple linear regression context, the fitted model is known as the
<strong>line of best fit</strong>.</p>
<p>In Figure <a href="linear-model-estimation.html#fig:rss-viz">6.3</a>, we visualize the response values, fitted
values, residuals, and fitted model in a simple linear regression
context. Note that:</p>
<ul>
<li>The fitted model is shown as the dashed grey line and minimizes the RSS.</li>
<li>The fitted values, shown as blue x’s, are the values returned by evaluating the fitted
model at the observed regressor values.</li>
<li>The residuals, shown as solid orange lines, indicate the distance and direction between the observed responses and their corresponding fitted value. If the response is larger than the fitted value then the residual is positive, otherwise it is negative.</li>
<li>The RSS is the sum of the squared vertical distances between the
response and fitted values.</li>
</ul>
<div class="figure"><span id="fig:rss-viz"></span>
<img src="Data-Analysis-with-Linear-Regression_files/figure-html/rss-viz-1.png" alt="Visualization of the response values, fitted values, residuals, and fitted model." width="672" />
<p class="caption">
Figure 6.3: Visualization of the response values, fitted values, residuals, and fitted model.
</p>
</div>
</div>
<div id="ols-estimators-of-the-simple-linear-regression-parameters" class="section level3" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> OLS estimators of the simple linear regression parameters</h3>
<p>The estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> that minimize the RSS for a
simple linear regression model can be obtained analytically using basic
calculus under minimal assumptions. Specifically, the optimal analytical
solutions for <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> are valid as long as
the regressor values are not a constant value, i.e, <span class="math inline">\(x_i \neq x_j\)</span> for
at least some <span class="math inline">\(i,j\in \{1,2,\ldots,n\}\)</span>.</p>
<p>Define <span class="math inline">\(\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i\)</span> and
<span class="math inline">\(\bar{Y} = \frac{1}{n}\sum_{i=1}^n Y_i\)</span>. The OLS estimators of the
simple linear regression coefficients are</p>
<p><span class="math display" id="eq:slr-beta1hat">\[\begin{align}
\hat{\beta}_1 &amp;= \frac{\sum_{i=1}^n x_i Y_i - \frac{1}{n} \biggl(\sum_{i=1}^n x_i\biggr)\biggl(\sum_{i=1}^n Y_i\biggr)}{\sum_{i=1}^n x_i^2 - \frac{1}{n} \biggl(\sum_{i=1}^n x_i\biggr)^2} \notag \\
&amp;= \frac{\sum_{i=1}^n (x_i - \bar{x})(Y_i - \bar{Y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \notag \\
&amp;= \frac{\sum_{i=1}^n (x_i - \bar{x})Y_i}{\sum_{i=1}^n (x_i - \bar{x})x_i} \tag{6.7}
\end{align}\]</span>
and
<span class="math display" id="eq:slr-beta0hat">\[\begin{equation}
\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{x}. \tag{6.8}
\end{equation}\]</span></p>
<p>We emphasize once again that the OLS estimators of <span class="math inline">\(\beta_0\)</span> and
<span class="math inline">\(\beta_1\)</span> are the estimators that minimize the RSS.</p>
<p>In edition to the regression coefficients, the other parameter we
discussed (in Section <a href="linear-model-estimation.html#ss-necessary-components">6.2.1</a>) is the error
variance, <span class="math inline">\(\sigma^2\)</span>. The most common estimator of the error variance is
<span class="math display" id="eq:sigmasq-hat">\[\begin{equation}
\hat{\sigma}^2 = \frac{RSS}{n-p}, \tag{6.9}
\end{equation}\]</span>
where <span class="math inline">\(p\)</span> is the number of regression coefficients. In
general, <span class="math inline">\(n-p\)</span> is the degrees of freedom of the RSS. In a simple linear
regression context, the denominator of Equation <a href="linear-model-estimation.html#eq:sigmasq-hat">(6.9)</a> is <span class="math inline">\(n-2\)</span>.</p>
</div>
</div>
<div id="s:penguins-slr" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Penguins simple linear regression example</h2>
<p>We will use the <code>penguins</code> data set in the <strong>palmerpenguins</strong> package
<span class="citation">(<a href="assumptions-stated-and-prioritized.html#ref-R-palmerpenguins" role="doc-biblioref">Horst, Hill, and Gorman 2020</a>)</span> to illustrate a very basic simple linear regression
analysis.</p>
<p>The <code>penguins</code> data set provides data related to various penguin species
measured in the Palmer Archipelago (Antarctica), originally provided by
<span class="citation"><a href="assumptions-stated-and-prioritized.html#ref-GormanEtAl2014" role="doc-biblioref">Gorman, Williams, and Fraser</a> (<a href="assumptions-stated-and-prioritized.html#ref-GormanEtAl2014" role="doc-biblioref">2014</a>)</span>. We start by loading the data into memory.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="linear-model-estimation.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(penguins, <span class="at">package =</span> <span class="st">&quot;palmerpenguins&quot;</span>)</span></code></pre></div>
<p>The data set includes 344 observations of
8 variables. The variables are:</p>
<ul>
<li><code>species</code>: a <code>factor</code> indicating the penguin species</li>
<li><code>island</code>: a <code>factor</code> indicating the island the penguin was observed</li>
<li><code>bill_length_mm</code>: a <code>numeric</code> variable indicating the bill length in
millimeters</li>
<li><code>bill_depth_mm</code>: a <code>numeric</code> variable indicating the bill depth in
millimeters</li>
<li><code>flipper_length_mm</code>: an <code>integer</code> variable indicating the flipper
length in millimeters</li>
<li><code>body_mass_g</code>: an <code>integer</code> variable indicating the body mass in
grams</li>
<li><code>sex</code>: a <code>factor</code> indicating the penguin sex (<code>female</code>, <code>male</code>)</li>
<li><code>year</code>: an integer denoting the study year the penguin was observed
(<code>2007</code>, <code>2008</code>, or <code>2009</code>)</li>
</ul>
<p>We begin by creating a scatter plot of <code>bill_length_mm</code> versus
<code>body_mass_g</code> (y-axis versus x-axis) in Figure <a href="linear-model-estimation.html#fig:penguin-plot">6.4</a>.
We see a clear positive association between body mass and bill length:
as the body mass increases, the bill length tends to increase. The
pattern is linear, i.e., roughly a straight line.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="linear-model-estimation.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bill_length_mm <span class="sc">~</span> body_mass_g, <span class="at">data =</span> penguins,</span>
<span id="cb2-2"><a href="linear-model-estimation.html#cb2-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;bill length (mm)&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;body mass (g)&quot;</span>,</span>
<span id="cb2-3"><a href="linear-model-estimation.html#cb2-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Penguin size measurements&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:penguin-plot"></span>
<img src="Data-Analysis-with-Linear-Regression_files/figure-html/penguin-plot-1.png" alt="A scatter plot of penguin bill length (mm) versus body mass (g)" width="672" />
<p class="caption">
Figure 6.4: A scatter plot of penguin bill length (mm) versus body mass (g)
</p>
</div>
<p>We first perform a single linear regression analysis manually using the
equations previously provided by regressing <code>bill_length_mm</code> on
<code>body_mass_g</code>.</p>
<p>Using the <code>summary</code> function on the <code>penguins</code> data frame, we see that
both <code>bill_length_mm</code> and <code>body_mass_g</code> have <code>NA</code> values.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="linear-model-estimation.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(penguins)</span></code></pre></div>
<pre><code>##       species          island    bill_length_mm  bill_depth_mm  
##  Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  
##  Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  
##  Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  
##                                  Mean   :43.92   Mean   :17.15  
##                                  3rd Qu.:48.50   3rd Qu.:18.70  
##                                  Max.   :59.60   Max.   :21.50  
##                                  NA&#39;s   :2       NA&#39;s   :2      
##  flipper_length_mm  body_mass_g       sex           year     
##  Min.   :172.0     Min.   :2700   female:165   Min.   :2007  
##  1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  
##  Median :197.0     Median :4050   NA&#39;s  : 11   Median :2008  
##  Mean   :200.9     Mean   :4202                Mean   :2008  
##  3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  
##  Max.   :231.0     Max.   :6300                Max.   :2009  
##  NA&#39;s   :2         NA&#39;s   :2</code></pre>
<p>We want to remove the rows of <code>penguins</code> where either <code>body_mass_g</code> or
<code>bill_length_mm</code> have <code>NA</code> values. We do that below using the <code>na.omit</code>
function (selecting only the relevant variables) and assign the cleaned
object the name <code>penguins_clean</code>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="linear-model-estimation.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># remove rows of penguins where bill_length_mm or body_mass_g have NA values </span></span>
<span id="cb5-2"><a href="linear-model-estimation.html#cb5-2" aria-hidden="true" tabindex="-1"></a>penguins_clean <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(penguins[,<span class="fu">c</span>(<span class="st">&quot;bill_length_mm&quot;</span>, <span class="st">&quot;body_mass_g&quot;</span>)])</span></code></pre></div>
<p>We extract the <code>bill_length_mm</code> variable from the <code>penguins</code> data frame
and assign it the name <code>y</code> since it will be the response variable. We
extract the <code>body_mass_g</code> variable from the <code>penguins</code> data frame and
assign it the name <code>y</code> since it will be the predictor variable. We also
determine the number of observations and assign that value the name <code>n</code>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="linear-model-estimation.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract response and predictor from penguins_clean</span></span>
<span id="cb6-2"><a href="linear-model-estimation.html#cb6-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> penguins_clean<span class="sc">$</span>bill_length_mm</span>
<span id="cb6-3"><a href="linear-model-estimation.html#cb6-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> penguins_clean<span class="sc">$</span>body_mass_g</span>
<span id="cb6-4"><a href="linear-model-estimation.html#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># determine number of observations</span></span>
<span id="cb6-5"><a href="linear-model-estimation.html#cb6-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span></code></pre></div>
<p>We now compute <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span>. Note that placing
<code>()</code> around the assignment operations will both perform the assign and
print the results.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="linear-model-estimation.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute OLS estimates of beta1 and beta0</span></span>
<span id="cb7-2"><a href="linear-model-estimation.html#cb7-2" aria-hidden="true" tabindex="-1"></a>(b1 <span class="ot">&lt;-</span> (<span class="fu">sum</span>(x <span class="sc">*</span> y) <span class="sc">-</span> <span class="fu">sum</span>(x) <span class="sc">*</span> <span class="fu">sum</span>(y) <span class="sc">/</span> n)<span class="sc">/</span>(<span class="fu">sum</span>(x<span class="sc">^</span><span class="dv">2</span>) <span class="sc">-</span> <span class="fu">sum</span>(x)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>n))</span></code></pre></div>
<pre><code>## [1] 0.004051417</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="linear-model-estimation.html#cb9-1" aria-hidden="true" tabindex="-1"></a>(b0 <span class="ot">&lt;-</span> <span class="fu">mean</span>(y) <span class="sc">-</span> b1 <span class="sc">*</span> <span class="fu">mean</span>(x))        </span></code></pre></div>
<pre><code>## [1] 26.89887</code></pre>
<p>The estimated value of <span class="math inline">\(\beta_0\)</span> is <span class="math inline">\(\hat{\beta}_0=26.90\)</span> and the
estimated value of <span class="math inline">\(\beta_1\)</span> is <span class="math inline">\(\hat{\beta}_1=0.004\)</span>. The basic
mathematical interpretation of our results is that:</p>
<ul>
<li>(<span class="math inline">\(\hat{\beta}_1\)</span>): If a penguin has a body mass 1 gram larger than
another penguin, we expect the larger penguins bill length to be
0.004 millimeters longer.</li>
<li>(<span class="math inline">\(\hat{\beta}_0\)</span>):A penguin with a body mass of 0 grams is expected
to have a bill length of 26.9 millimeters.</li>
</ul>
<p>The latter interpretation is clearly non-sensical and is caused by the
fact that we are extrapolating far outside the observed body mass
values. The relationship between body mass and bill length is different
for penguin chicks versus adults.</p>
<p>We can use the <code>abline</code> function to overlay the fitted model on the
observed data. Note that in simple linear regression, <span class="math inline">\(\hat{\beta}_1\)</span>
corresponds to the slope of the fitted line and <span class="math inline">\(\hat{\beta}_0\)</span> will be
the intercept.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="linear-model-estimation.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bill_length_mm <span class="sc">~</span> body_mass_g, <span class="at">data =</span> penguins,</span>
<span id="cb11-2"><a href="linear-model-estimation.html#cb11-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;bill length (mm)&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;body mass (g)&quot;</span>,</span>
<span id="cb11-3"><a href="linear-model-estimation.html#cb11-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Penguin size measurements&quot;</span>)</span>
<span id="cb11-4"><a href="linear-model-estimation.html#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># a is the intercept and b is the slope</span></span>
<span id="cb11-5"><a href="linear-model-estimation.html#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> b0, <span class="at">b =</span> b1)</span></code></pre></div>
<p><img src="Data-Analysis-with-Linear-Regression_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The fit of the model to our observed data seems reasonable.</p>
<p>We can also compute the residuals,
<span class="math inline">\(\hat{\epsilon}_1,\ldots,\hat{\epsilon}_n\)</span>, the fitted values
<span class="math inline">\(\hat{y}_1,\ldots,\hat{y}_n\)</span>, and the associated RSS,
<span class="math inline">\(RSS=\sum_{i=1}^n \hat{\epsilon}_i^2\)</span>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="linear-model-estimation.html#cb12-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> b0 <span class="sc">+</span> b1 <span class="sc">*</span> x <span class="co"># compute fitted values</span></span>
<span id="cb12-2"><a href="linear-model-estimation.html#cb12-2" aria-hidden="true" tabindex="-1"></a>ehat <span class="ot">&lt;-</span> y <span class="sc">-</span> yhat <span class="co"># compute residuals</span></span>
<span id="cb12-3"><a href="linear-model-estimation.html#cb12-3" aria-hidden="true" tabindex="-1"></a>(rss <span class="ot">&lt;-</span> <span class="fu">sum</span>(ehat<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># sum of the squared residuals</span></span></code></pre></div>
<pre><code>## [1] 6564.494</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="linear-model-estimation.html#cb14-1" aria-hidden="true" tabindex="-1"></a>(sigmasqhat <span class="ot">&lt;-</span> rss<span class="sc">/</span>(n<span class="dv">-2</span>)) <span class="co"># estimated error variance</span></span></code></pre></div>
<pre><code>## [1] 19.30734</code></pre>
</div>
<div id="estimation-of-the-multiple-linear-regression-coefficients" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Estimation of the multiple linear regression coefficients)</h2>
<p>We now consider the context where we want to estimate the parameters of
a linear model with 1 or more regressors, i.e., when
<span class="math display">\[Y=\beta_0 + \beta_1 X_1 + \cdots + \beta_{p-1} X_{p-1} + \epsilon.\]</span></p>
<p>The multiple linear regression model relating the responses, the regressors, and the errors for all <span class="math inline">\(n\)</span> observations is defined by the system of equations
<span class="math display" id="eq:lmSystem">\[\begin{equation}
Y_i = \beta_0 + \beta_1 x_{i,1} + \beta_2 x_{i,2} + \cdots + \beta_{p-1} x_{i,p-1} + \epsilon_i,\quad i=1,2,\ldots,n.
\tag{6.10}
\end{equation}\]</span></p>
<div id="using-matrix-notation-to-represent-a-linear-model" class="section level3" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Using matrix notation to represent a linear model</h3>
<p>To simplify estimation of the regression coefficients in a linear
regression model, we must use matrix notation to describe the system of
equation defining our linear model.</p>
<p>We define the following notation:</p>
<ul>
<li><span class="math inline">\(\mathbf{y} = [Y_1, Y_2, \ldots, Y_n]\)</span> denotes the column vector
containing the <span class="math inline">\(n\)</span> responses.</li>
<li><span class="math inline">\(\mathbf{X}\)</span> denotes the matrix containing a column of 1s and the
observed regressor values, specifically,
<span class="math display">\[\mathbf{X} = \begin{bmatrix}
1 &amp; x_{1,1} &amp; x_{1,2} &amp; \cdots &amp; x_{1,p-1} \\
1 &amp; x_{2,1} &amp; x_{2,2} &amp; \cdots &amp; x_{2,p-1} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
1 &amp; x_{n,1} &amp; x_{n,2} &amp; \cdots &amp; x_{n,p-1}
\end{bmatrix}.\]</span></li>
<li><span class="math inline">\(\boldsymbol{\beta} = [\beta_0, \beta_1, \ldots, \beta_{p-1}]\)</span>
denotes the column vector containing the <span class="math inline">\(p\)</span> regression
coefficients.</li>
<li><span class="math inline">\(\boldsymbol{\epsilon} = [\epsilon_1, \epsilon_2, \ldots, \epsilon_n]\)</span>
denotes the column vector contained the <span class="math inline">\(n\)</span> errors.</li>
</ul>
<p>Then the system of equations defining the linear model in
<a href="linear-model-estimation.html#eq:lmSystem">(6.10)</a> can be written as
<span class="math display">\[\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}.\]</span>
Thus, a linear model can be represented as a system of linear equations
using matrices. A model that cannot be represented as a system of linear
equations using matrices is not a linear model.</p>
</div>
<div id="ss:fv-resid-rss-mlr" class="section level3" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Residuals, fitted values, and RSS for multiple linear regression</h3>
<p>We proceed with discussion of residuals, fitted values, and RSS for the multiple linear regression context using matrix notation.</p>
<p>The vector of estimated values for the coefficients contained in <span class="math inline">\(\boldsymbol{\beta}\)</span> is denoted by
<span class="math display" id="eq:def-beta-matrix">\[\begin{equation}
\hat{\boldsymbol{\beta}}=[\hat{\beta}_0,\hat{\beta}_1,\ldots,\hat{\beta}_{p-1}]. \tag{6.11}
\end{equation}\]</span></p>
<p>The vector of regressor values for the <span class="math inline">\(i\)</span>th observation is denoted by
<span class="math display" id="eq:def-ith-regressor-matrix">\[\begin{equation}
\mathbf{x}_i=[1,x_{i,1},\ldots,x_{i,p-1}], \tag{6.12}
\end{equation}\]</span>
where the 1 is needed to account for the intercept in our model.</p>
<p>Extending the original definition of a fitted value in Equation <a href="linear-model-estimation.html#eq:def-fitted-value-slr">(6.3)</a>, the <span class="math inline">\(i\)</span>th fitted value in the context of multiple linear regression is defined as
<span class="math display" id="eq:def-fitted-value-matrix">\[\begin{align}
\hat{Y}_i &amp;= \hat{E}(Y|\mathbb{X} = \mathbf{x}_i) \notag \\
&amp;= \hat{\beta}_0 + \hat{\beta}_1 x_{i,1} + \cdots + \hat{\beta}_{p-1} x_{i,p-1} \notag \\
&amp;= \mathbf{x}_i^T\hat{\boldsymbol{\beta}}. \tag{6.13}
\end{align}\]</span></p>
<p>The (column) vector of fitted values is defined as
<span class="math display" id="eq:def-fitted-values-matrix">\[\begin{equation}
\hat{\mathbf{y}} = [\hat{Y}_1,\ldots,\hat{Y}_n]. \tag{6.14}
\end{equation}\]</span></p>
<p>Extending the original definition of a residual in Equation <a href="linear-model-estimation.html#eq:def-residual-slr">(6.4)</a>,
the <span class="math inline">\(i\)</span>th residual in the context of multiple linear regression can be written as
\begin{align}
_i = Y_i - _i=Y_i-_i^T,
\end{equation}
using Equation <a href="linear-model-estimation.html#eq:def-fitted-value-matrix">(6.13)</a>.</p>
<p>The RSS for a simple linear regression model, as a function of the
estimated regression coefficients, is <span class="math display">\[\begin{align*}
RSS(\hat{\beta}_0, \hat{\beta}_1) &amp;= \sum_{i=1}^n \hat{\epsilon}_i^2 \\
&amp;= \sum_{i=1}^n (Y_i - \hat{Y}_i)^2 \\
&amp;= \sum_{i=1}^n (Y_i - \hat{E}(Y|X=x_i))^2 \\
 &amp;= \sum_{i=1}^n (Y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i))^2.
\end{align*}\]</span></p>
</div>
<div id="ols-estimator-of-the-linear-model-parameters" class="section level3" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> OLS estimator of the linear model parameters</h3>
<p>The OLS estimator of the regression coefficient vector,
<span class="math inline">\(\boldsymbol{\beta}\)</span>, is</p>
<span class="math display" id="eq:slr-beta1hat" id="eq:slr-beta0hat" id="eq:slr-beta1hat" id="eq:betahat">\[\begin{equation}
\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}, \tag{6.15}
\end{equation}\]</span>
</div>
</div>
<div id="s:penguins-mlr" class="section level2" number="6.6">
<h2><span class="header-section-number">6.6</span> Penguins multiple linear regression example</h2>
<p>The data set includes 344 observations of
8 variables. The variables are:</p>
<ul>
<li><code>species</code>: a <code>factor</code> indicating the penguin species</li>
<li><code>island</code>: a <code>factor</code> indicating the island the penguin was observed</li>
<li><code>bill_length_mm</code>: a <code>numeric</code> variable indicating the bill length in
millimeters</li>
<li><code>bill_depth_mm</code>: a <code>numeric</code> variable indicating the bill depth in
millimeters</li>
<li><code>flipper_length_mm</code>: an <code>integer</code> variable indicating the flipper
length in millimeters</li>
<li><code>body_mass_g</code>: an <code>integer</code> variable indicating the body mass in
grams</li>
<li><code>sex</code>: a <code>factor</code> indicating the penguin sex (<code>female</code>, <code>male</code>)</li>
<li><code>year</code>: an integer denoting the study year the penguin was observed
(<code>2007</code>, <code>2008</code>, or <code>2009</code>)</li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="linear-model-estimation.html#cb16-1" aria-hidden="true" tabindex="-1"></a>mlmod <span class="ot">&lt;-</span> <span class="fu">lm</span>(bill_length_mm <span class="sc">~</span> body_mass_g <span class="sc">+</span> flipper_length_mm, <span class="at">data =</span> penguins)</span>
<span id="cb16-2"><a href="linear-model-estimation.html#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mlmod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bill_length_mm ~ body_mass_g + flipper_length_mm, 
##     data = penguins)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.8064 -2.5898 -0.7053  1.9911 18.8288 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       -3.4366939  4.5805532  -0.750    0.454    
## body_mass_g        0.0006622  0.0005672   1.168    0.244    
## flipper_length_mm  0.2218655  0.0323484   6.859 3.31e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.124 on 339 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.4329, Adjusted R-squared:  0.4295 
## F-statistic: 129.4 on 2 and 339 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="categorical-predictors" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> Categorical predictors</h2>
</div>
<div id="s:penguins-mlr" class="section level2" number="6.8">
<h2><span class="header-section-number">6.8</span> Penguins multiple linear regression example with categorical predictor</h2>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="linear-model-estimation.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb18-2"><a href="linear-model-estimation.html#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> penguins) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> body_mass_g, <span class="at">y =</span> bill_length_mm, <span class="at">col =</span> species))</span></code></pre></div>
<pre><code>## Warning: Removed 2 rows containing missing values (geom_point).</code></pre>
<p><img src="Data-Analysis-with-Linear-Regression_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="linear-model-estimation.html#cb20-1" aria-hidden="true" tabindex="-1"></a>lmodb <span class="ot">&lt;-</span> <span class="fu">lm</span>(bill_length_mm <span class="sc">~</span> body_mass_g <span class="sc">+</span> species <span class="sc">+</span> body_mass_g<span class="sc">:</span>species, <span class="at">data =</span> penguins)</span>
<span id="cb20-2"><a href="linear-model-estimation.html#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lmodb)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bill_length_mm ~ body_mass_g + species + body_mass_g:species, 
##     data = penguins)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.4208 -1.6461  0.0919  1.4718  9.3138 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                  26.9941391  1.5926015  16.950  &lt; 2e-16 ***
## body_mass_g                   0.0031879  0.0004271   7.464 7.27e-13 ***
## speciesChinstrap              5.1800537  3.2746719   1.582    0.115    
## speciesGentoo                -0.2545907  2.7138655  -0.094    0.925    
## body_mass_g:speciesChinstrap  0.0012748  0.0008740   1.459    0.146    
## body_mass_g:speciesGentoo     0.0009030  0.0006066   1.489    0.138    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.399 on 336 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.8098, Adjusted R-squared:  0.807 
## F-statistic: 286.1 on 5 and 336 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="linear-model-estimation.html#cb22-1" aria-hidden="true" tabindex="-1"></a>lmodc <span class="ot">&lt;-</span> <span class="fu">lm</span>(bill_length_mm <span class="sc">~</span> body_mass_g<span class="sc">*</span>species, <span class="at">data =</span> penguins)</span>
<span id="cb22-2"><a href="linear-model-estimation.html#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coefficients</span>(lmodb)</span></code></pre></div>
<pre><code>##                  (Intercept)                  body_mass_g 
##                26.9941391367                 0.0031878758 
##             speciesChinstrap                speciesGentoo 
##                 5.1800537287                -0.2545906615 
## body_mass_g:speciesChinstrap    body_mass_g:speciesGentoo 
##                 0.0012748183                 0.0009029956</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="linear-model-estimation.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coefficients</span>(lmodc)</span></code></pre></div>
<pre><code>##                  (Intercept)                  body_mass_g 
##                26.9941391367                 0.0031878758 
##             speciesChinstrap                speciesGentoo 
##                 5.1800537287                -0.2545906615 
## body_mass_g:speciesChinstrap    body_mass_g:speciesGentoo 
##                 0.0012748183                 0.0009029956</code></pre>
</div>
<div id="evaluating-model-fit" class="section level2" number="6.9">
<h2><span class="header-section-number">6.9</span> Evaluating model fit</h2>
</div>
<div id="summary-of-notation" class="section level2" number="6.10">
<h2><span class="header-section-number">6.10</span> Summary of notation</h2>
</div>
<div id="summary-of-functions-used-in-this-chapter" class="section level2" number="6.11">
<h2><span class="header-section-number">6.11</span> Summary of functions used in this chapter</h2>
</div>
<div id="summarizing-the-components-of-a-linear-model-1" class="section level2" number="6.12">
<h2><span class="header-section-number">6.12</span> Summarizing the components of a linear model</h2>
<p>We have already introduced a lot of objects. To aid in making sense of
their notation, their purpose in the model, whether they can be
observed, and whether they are modeled as a random variable (vector) or
fixed, non-random values, we summarize things below.</p>
<p>We’ve already talked about observing the response variable and the
predictor variables. So these objects are observable. However, we have
no way to measure the regression coefficients or the error. These are
not observable.</p>
<p>On the other hand, we treat the response variable as a random variable.
Perhaps surprisingly, we treated the predictor variables as a fixed,
non-random variables. The regression coefficients are treated as fixed,
non-random but unknown values. This is standard for parameters in a
statistical model. The errors are also treated as random variables. In
fact, since both the predictor variables and the regression coefficients
are non-random, the only way for the response to be a random variable
based on Equation <a href="linear-model-estimation.html#eq:lmSystem">(6.10)</a> is for the errors to be random.</p>
<p>We summarize this information in the table below for the objects
previously discussed using the various notations introduced.</p>
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Notation</th>
<th>Description</th>
<th>Observable</th>
<th>Random</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(Y\)</span></td>
<td>response
variable</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td><span class="math inline">\(Y_i\)</span></td>
<td>response value
for the <span class="math inline">\(i\)</span>th
observation</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathbf{y}\)</span></td>
<td>the <span class="math inline">\(n\times 1\)</span>
column vector
of response
values</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td><span class="math inline">\(X\)</span></td>
<td>regressor
variable</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X_j\)</span></td>
<td>the <span class="math inline">\(j\)</span>th
regressor
variable</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="even">
<td><span class="math inline">\(x_{i,j}\)</span></td>
<td>the value of
the <span class="math inline">\(j\)</span>th
regressor
variable for
the <span class="math inline">\(i\)</span>th
observation</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathbf{X}\)</span></td>
<td>the <span class="math inline">\(n\times p\)</span>
matrix of
regressor
values</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\beta_j\)</span></td>
<td>the regression
coefficient
associated with
the <span class="math inline">\(j\)</span>th
regressor
variable</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="odd">
<td>$\boldsymbol{</td>
<td>a}$| the $p
column vector
of regression
coefficients</td>
<td>1$ | No</td>
<td>| No</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\epsilon\)</span></td>
<td>the error</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\epsilon_i\)</span></td>
<td>the error
associated with
observation <span class="math inline">\(i\)</span></td>
<td>No</td>
<td>Yes</td>
</tr>
</tbody>
</table>
</div>
<div id="going-deeper" class="section level2" number="6.13">
<h2><span class="header-section-number">6.13</span> Going Deeper</h2>
<div id="manually-estimating-the-simple-linear-regression-coefficients" class="section level3" number="6.13.1">
<h3><span class="header-section-number">6.13.1</span> Manually estimating the simple linear regression coefficients</h3>
<p>In this section we will manually perform the Penguins simple linear regression
analysis provided in Section @ref{s:penguins-slr}.</p>
<p>Recall that the <code>penguins</code> data frame in the **palmerpenguins* package contained
the variables:</p>
<ul>
<li><code>bill_length_mm</code>: a <code>numeric</code> variable indicating the bill length in
millimeters</li>
<li><code>body_mass_g</code>: an <code>integer</code> variable indicating the body mass in
grams</li>
</ul>
<p>We will use formulas for <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> in
Equations @ref\tag{6.7}
and @ref\tag{6.8} to manually compute the estimated regression
coefficients for the simple linear regression model when
regressing <code>bill_length_mm</code> on <code>body_mass_g</code>.</p>
<p>We first load the <code>penguins</code> data frame. We then select the <code>bill_length_mm</code> and <code>body_mass_g</code> variables of the data frame and use the pipe operator to pass the simplified data frame to the <code>summary</code> function.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="linear-model-estimation.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(penguins, <span class="at">package =</span> <span class="st">&quot;palmerpenguins&quot;</span>) <span class="co"># load data</span></span>
<span id="cb26-2"><a href="linear-model-estimation.html#cb26-2" aria-hidden="true" tabindex="-1"></a>penguins[,<span class="fu">c</span>(<span class="st">&quot;bill_length_mm&quot;</span>, <span class="st">&quot;body_mass_g&quot;</span>)] <span class="sc">|</span><span class="er">&gt;</span> <span class="fu">summary</span>() <span class="co"># simplify and summarize</span></span></code></pre></div>
<pre><code>##  bill_length_mm   body_mass_g  
##  Min.   :32.10   Min.   :2700  
##  1st Qu.:39.23   1st Qu.:3550  
##  Median :44.45   Median :4050  
##  Mean   :43.92   Mean   :4202  
##  3rd Qu.:48.50   3rd Qu.:4750  
##  Max.   :59.60   Max.   :6300  
##  NA&#39;s   :2       NA&#39;s   :2</code></pre>
<p>Both <code>bill_length_mm</code> and <code>body_mass_g</code> have <code>NA</code> values that will poison our calculations if we naively use those variables in our calculations, so we must remove them prior to calculation.</p>
<p>The <code>na.omit</code> function attempts to handle missing values in R objects. The <code>penguins</code> data frame has class <code>data.frame</code>. For a <code>data.frame</code>, <code>na.omit</code> will remove any rows that have <code>NA</code> values. Note that if you are only concerned with the <code>NA</code> values for certain variables of a data frame then you should apply the <code>na.omit</code> to the data frame containing only those variables, otherwise <code>na.omit</code> may remove rows unnecessarily because a different variable has an <code>NA</code> value.</p>
<p>Compare the dimensions of the results when we apply <code>na.omit</code> to <code>penguins</code> versus
<code>penguins</code> with only <code>bill_length_mm</code> and <code>body_mass_g</code>.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="linear-model-estimation.html#cb28-1" aria-hidden="true" tabindex="-1"></a>penguins <span class="sc">|</span><span class="er">&gt;</span> <span class="fu">na.omit</span>() <span class="sc">|</span><span class="er">&gt;</span> <span class="fu">dim</span>() <span class="co"># dimensions penguins after filtering rows with NA</span></span></code></pre></div>
<pre><code>## [1] 333   8</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="linear-model-estimation.html#cb30-1" aria-hidden="true" tabindex="-1"></a>penguins[,<span class="fu">c</span>(<span class="st">&quot;bill_length_mm&quot;</span>, <span class="st">&quot;body_mass_g&quot;</span>)] <span class="sc">|</span><span class="er">&gt;</span> <span class="fu">na.omit</span>() <span class="sc">|</span><span class="er">&gt;</span> <span class="fu">dim</span>()</span></code></pre></div>
<pre><code>## [1] 342   2</code></pre>
<p>The data frame obtained after applying <code>na.omit</code> to the <code>penguins</code>
data frame has only 333 rows, while the data frame obtained by applying <code>na.omit</code>
to only the <code>bill_length_mm</code> and <code>body_mass_g</code> columns of <code>penguins</code> has 342 rows. This
is because some of the other variables in <code>penguins</code> have <code>NA</code> values in rows that
the <code>bill_length_mm</code> and <code>body_mass_g</code> columns do not, so the <code>na.omit</code> function must remove
additional rows.</p>
<p>Continuing our analysis, we create a new data frame, <code>penguins_clean</code>, that is
obtained by selecting the <code>bill_length_mm</code> and <code>body_mass_g</code> variables of <code>penguins</code> and
then using the <code>na.omit</code> function to retain only the rows without <code>NA</code> values.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="linear-model-estimation.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># remove rows of penguins where bill_length_mm or body_mass_g have NA values </span></span>
<span id="cb32-2"><a href="linear-model-estimation.html#cb32-2" aria-hidden="true" tabindex="-1"></a>penguins_clean <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(penguins[,<span class="fu">c</span>(<span class="st">&quot;bill_length_mm&quot;</span>, <span class="st">&quot;body_mass_g&quot;</span>)])</span></code></pre></div>
<p>We extract the <code>bill_length_mm</code> variable from the <code>penguins_clean</code> data frame
and assign it the name <code>y</code> since it will be the response variable. We
extract the <code>body_mass_g</code> variable from the <code>penguins</code> data frame and
assign it the name <code>x</code> since it will be the regressor variable. We also
determine the number of observations and assign that value the name <code>n</code>.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="linear-model-estimation.html#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract response and regressor from penguins_clean</span></span>
<span id="cb33-2"><a href="linear-model-estimation.html#cb33-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> penguins_clean<span class="sc">$</span>bill_length_mm</span>
<span id="cb33-3"><a href="linear-model-estimation.html#cb33-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> penguins_clean<span class="sc">$</span>body_mass_g</span>
<span id="cb33-4"><a href="linear-model-estimation.html#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># determine number of observations</span></span>
<span id="cb33-5"><a href="linear-model-estimation.html#cb33-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span></code></pre></div>
<p>We now compute <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span> using the formulas in Equations @ref\tag{6.7} and @ref\tag{6.8}, respectively. Note that placing
<code>()</code> around the assignment operations will both perform the assignment and
print the results.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="linear-model-estimation.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute OLS estimates of beta1 and beta0</span></span>
<span id="cb34-2"><a href="linear-model-estimation.html#cb34-2" aria-hidden="true" tabindex="-1"></a>(b1 <span class="ot">&lt;-</span> (<span class="fu">sum</span>(x <span class="sc">*</span> y) <span class="sc">-</span> <span class="fu">sum</span>(x) <span class="sc">*</span> <span class="fu">sum</span>(y) <span class="sc">/</span> n)<span class="sc">/</span>(<span class="fu">sum</span>(x<span class="sc">^</span><span class="dv">2</span>) <span class="sc">-</span> <span class="fu">sum</span>(x)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>n))</span></code></pre></div>
<pre><code>## [1] 0.004051417</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="linear-model-estimation.html#cb36-1" aria-hidden="true" tabindex="-1"></a>(b0 <span class="ot">&lt;-</span> <span class="fu">mean</span>(y) <span class="sc">-</span> b1 <span class="sc">*</span> <span class="fu">mean</span>(x))        </span></code></pre></div>
<pre><code>## [1] 26.89887</code></pre>
<p>The estimated value of <span class="math inline">\(\beta_0\)</span> is $_0=$0 and the
estimated value of <span class="math inline">\(\beta_1\)</span> is <span class="math inline">\(\hat{\beta}_1=0.004\)</span>. The basic
mathematical interpretation of our results is that:</p>
<ul>
<li><span class="math inline">\(\hat{\beta}_1\)</span>: If a penguin has a body mass 1 gram larger than
another penguin, we expect the larger penguins bill length to be
0.004 millimeters longer.</li>
<li><span class="math inline">\(\hat{\beta}_0\)</span>:A penguin with a body mass of 0 grams is expected
to have a bill length of 26.9 millimeters.</li>
</ul>
<p>The latter interpretation is clearly non-sensical and is caused by the
fact that we are extrapolating far outside the observed body mass
values. The relationship between body mass and bill length is different
for penguin chicks versus adults.</p>
<p>We can use the <code>abline</code> function to overlay the fitted model on the
observed data. Note that in simple linear regression, <span class="math inline">\(\hat{\beta}_1\)</span>
corresponds to the slope of the fitted line and <span class="math inline">\(\hat{\beta}_0\)</span> will be
the intercept.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="linear-model-estimation.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bill_length_mm <span class="sc">~</span> body_mass_g, <span class="at">data =</span> penguins,</span>
<span id="cb38-2"><a href="linear-model-estimation.html#cb38-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;bill length (mm)&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;body mass (g)&quot;</span>,</span>
<span id="cb38-3"><a href="linear-model-estimation.html#cb38-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Penguin size measurements&quot;</span>)</span>
<span id="cb38-4"><a href="linear-model-estimation.html#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># a is the intercept and b is the slope</span></span>
<span id="cb38-5"><a href="linear-model-estimation.html#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> b0, <span class="at">b =</span> b1)</span></code></pre></div>
<p><img src="Data-Analysis-with-Linear-Regression_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>The fit of the model to our observed data seems reasonable.</p>
<p>We can also compute the residuals,
<span class="math inline">\(\hat{\epsilon}_1,\ldots,\hat{\epsilon}_n\)</span>, the fitted values
<span class="math inline">\(\hat{y}_1,\ldots,\hat{y}_n\)</span>, and the associated RSS,
<span class="math inline">\(RSS=\sum_{i=1}^n \hat{\epsilon}_i^2\)</span>.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="linear-model-estimation.html#cb39-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> b0 <span class="sc">+</span> b1 <span class="sc">*</span> x <span class="co"># compute fitted values</span></span>
<span id="cb39-2"><a href="linear-model-estimation.html#cb39-2" aria-hidden="true" tabindex="-1"></a>ehat <span class="ot">&lt;-</span> y <span class="sc">-</span> yhat <span class="co"># compute residuals</span></span>
<span id="cb39-3"><a href="linear-model-estimation.html#cb39-3" aria-hidden="true" tabindex="-1"></a>(rss <span class="ot">&lt;-</span> <span class="fu">sum</span>(ehat<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># sum of the squared residuals</span></span></code></pre></div>
<pre><code>## [1] 6564.494</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="linear-model-estimation.html#cb41-1" aria-hidden="true" tabindex="-1"></a>(sigmasqhat <span class="ot">&lt;-</span> rss<span class="sc">/</span>(n<span class="dv">-2</span>)) <span class="co"># estimated error variance</span></span></code></pre></div>
<pre><code>## [1] 19.30734</code></pre>
</div>
<div id="manually-estimating-the-multiple-linear-regression-coefficients" class="section level3" number="6.13.2">
<h3><span class="header-section-number">6.13.2</span> Manually estimating the multiple linear regression coefficients</h3>
</div>
<div id="parameter-estimation-and-matrix-decompositions" class="section level3" number="6.13.3">
<h3><span class="header-section-number">6.13.3</span> Parameter estimation and matrix decompositions</h3>
</div>
<div id="updating-a-model" class="section level3" number="6.13.4">
<h3><span class="header-section-number">6.13.4</span> Updating a model</h3>
</div>
<div id="more-discussion-of-formula-for-model-building" class="section level3" number="6.13.5">
<h3><span class="header-section-number">6.13.5</span> More discussion of <code>formula</code> for model-building</h3>
<p>The models fit by, e.g., the lm and glm functions are specified in a
compact symbolic form. The ~ operator is basic in the formation of such
models. An expression of the form y ~ model is interpreted as a
specification that the response y is modelled by a linear predictor
specified symbolically by model. Such a model consists of a series of
terms separated by + operators. The terms themselves consist of variable
and factor names separated by : operators. Such a term is interpreted as
the interaction of all the variables and factors appearing in the term.</p>
<p>In addition to + and :, a number of other operators are useful in model
formulae. The * operator denotes factor crossing: a<em>b interpreted as
a+b+a:b. The ^ operator indicates crossing to the specified degree. For
example (a+b+c)^2 is identical to (a+b+c)</em>(a+b+c) which in turn expands
to a formula containing the main effects for a, b and c together with
their second-order interactions. The %in% operator indicates that the
terms on its left are nested within those on the right. For example a +
b %in% a expands to the formula a + a:b. The - operator removes the
specified terms, so that (a+b+c)^2 - a:b is identical to a + b + c +
b:c + a:c. It can also used to remove the intercept term: when fitting a
linear model y ~ x - 1 specifies a line through the origin. A model
with no intercept can be also specified as y ~ x + 0 or y ~ 0 + x.</p>
<p>While formulae usually involve just variable and factor names, they can
also involve arithmetic expressions. The formula log(y) ~ a + log(x) is
quite legal. When such arithmetic expressions involve operators which
are also used symbolically in model formulae, there can be confusion
between arithmetic and symbolic operator use.</p>
<p>To avoid this confusion, the function I() can be used to bracket those
portions of a model formula where the operators are used in their
arithmetic sense. For example, in the formula y ~ a + I(b+c), the term
b+c is to be interpreted as the sum of b and c.</p>
<p>Variable names can be quoted by backticks <code>like this</code> in formulae,
although there is no guarantee that all code using formulae will accept
such non-syntactic names.</p>
<p>Most model-fitting functions accept formulae with right-hand-side
including the function offset to indicate terms with a fixed coefficient
of one. Some functions accept other ‘specials’ such as strata or cluster
(see the specials argument of terms.formula).</p>
<p>There are two special interpretations of . in a formula. The usual one
is in the context of a data argument of model fitting functions and
means ‘all columns not otherwise in the formula’: see terms.formula. In
the context of update.formula, only, it means ‘what was previously in
this part of the formula.’</p>
<p>When formula is called on a fitted model object, either a specific
method is used (such as that for class “nls”) or the default method. The
default first looks for a “formula” component of the object (and
evaluates it), then a “terms” component, then a formula parameter of the
call (and evaluates its value) and finally a “formula” attribute.</p>
<p>There is a formula method for data frames. When there’s “terms”
attribute with a formula, e.g., for a model.frame(), that formula is
returned. If you’d like the previous (R &lt;= 3.5.x) behavior, use the
auxiliary DF2formula() which does not consider a “terms” attribute.
Otherwise, if there is only one column this forms the RHS with an empty
LHS. For more columns, the first column is the LHS of the formula and
the remaining columns separated by + form the RHS.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="defining-and-fitting-a-linear-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="parameter-estimation-for-linear-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Data-Analysis-with-Linear-Regression.pdf", "Data-Analysis-with-Linear-Regression.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
