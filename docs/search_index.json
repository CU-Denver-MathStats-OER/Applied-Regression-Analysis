[
["r-foundations.html", "Data Analysis with Linear Regression Chapter 1 R Foundations 1.1 What is R? 1.2 Where to get R (and R Studio Desktop) 1.3 R Studio Layout 1.4 Running code, scripts, and comments 1.5 Packages 1.6 Getting help 1.7 Data types and structures 1.8 Assignment 1.9 Vectors 1.10 Helpful functions 1.11 Data Frames 1.12 Logical statements 1.13 Subsetting with logical statements 1.14 Ecosystem debate", " Data Analysis with Linear Regression Joshua French 2021-01-21 Chapter 1 R Foundations Meaningful data analysis requires the use of computer software. In this course, we will utilize R. In what follows, I will attempt to lay a foundation of key components of R that you will need for data analysis. I make no attempt to be exhaustive, and many other important components of R (like plotting) will be discussed later, as needed. 1.1 What is R? R is programming language and environment designed for statistical computing. It was introduced by Robert Gentleman and Robert Ihaka in 1993. It is modeled after the S programming language. R is free, open source, and runs on Windows, Macs, Linux, and other types of computers. R is an interactive programming language You type and execute a command in the Console for immediate feedback in contrast to a compiled programming language, which compiles a program that is then executed. R is highly extendable. Many user-created packages are available to extend the functionality beyond what is installed by default. Users can write their own functions and easily add software libraries to R. 1.2 Where to get R (and R Studio Desktop) R may be downloaded from the R Project’s website. This link should bring you to the relevant page for downloading the software. R Studio Desktop is a free “front end” for R provided by R Studio. R Studio Desktop makes doing data science with R much easier by adding an Integrated Development Environment (IDE) and providing many other features. Currently, you may download R Studio at this link. You may need to navigate the R Studio website directly if this link no longer functions. Install R and R Studio Desktop before continuing. Then open R Studio Desktop as you continue to learn about R. 1.3 R Studio Layout R Studio Desktop has four panes: Console: the pane where the code is executed. Source: the pane where you prepare commands to be executed. Environment/History: the pane where you can see all the objects in your workspace, your command history, and other things. The Files/Plot/Packages/Help: the pane where you navigate between directories, where plots can be viewed, where you can see the packages available to be loaded, and where you can get help. RStudio panes 1.4 Running code, scripts, and comments Code is executed in R by typing it in the Console and hitting enter. Instead of typing all of your code in the Console and hitting enter, it’s better to write your code in a Script and execute the code separately. A new script can be obtained by executing File -&gt; New File -&gt; R Script or pressing “Ctrl + Shift + n” (on a PC) or “Cmd + Shift + n” on a Mac. There are various ways to run code from a Script file. The most common ones are: Highlight the code you want to run and hit the Run button at the top of the Script pane. Highlight the code you want to run and press “Ctrl + Enter” on your keyboard. If you don’t highlight anything, by default, R Studio runs the command the cursor currently lies on. To save a script, click File -&gt; Save or press “Ctrl + s” (on a PC) or “Cmd + s” (on a Mac). A comment is a set of text ignored by R when submitted to the Console. A comment is indicated by the # symbol. Nothing to the right of the # is executed in the Console. To comment (or uncomment) multiple lines in R, highlight the code you want to comment and press “Ctrl + Shift + c” on a PC or “Cmd + Shift + c” on a Mac. 1.4.1 Example Perform the following tasks: Type 1+1 in the Console and hit enter. Open a new Script in R Studio. mean(1:3) in your Script file. Type # mean(1:3) in your Script file. Run the commands from the Script using an approach mentioned above. 1.5 Packages Packages are collections of functions, data, and other objects that extend the functionality installed by default in R. R packages can be installed using the install.packages function and loaded using the library function. 1.5.1 Example Practice installing and loading a package by doing the following: Install the set of faraway package by executing the command install.packages(\"faraway\"). Load the faraway package by executing the command library(faraway). 1.6 Getting help There are a number of helps to get help in R. If you know the command for which you want help, then exectue ?command in the Console. * e.g., ?lm * This also may work with data sets, package names, object classes, etc. If you want to search the documentation for a certain topic, then execute ??topic in the Console. * If you need help deciphering an error, identifying packages to perform a certain analysis, how to do something better, then a web search is likely to help. 1.6.1 Example Do the following: 1. Execute ?lm in the Console to get help on the lm function, which is one of the main functions used for fitting linear models. 2. Execute ??logarithms in the Console to search the R documentation for information about logarithms. 3. Do a web search for something along the lines of “How do I change the size of the axis labels in an R plot?”. 1.7 Data types and structures 1.7.1 Basic data types R has 6 basic (“atomic”) vector types: character - collections of characters. E.g., \"a\", “hello world!” double - decimal numbers. e.g., 1.2, 1.0 integer - whole numbers. In R, you must add L to the end of a number to specify it as an integer. E.g., 1L is an integer but 1 is a double. logical - boolean values, TRUE and FALSE complex - complex numbers. E.g., 1+3i raw - a type to hold raw bytes. The typeof function returns the R internal type or storage mode of any object. Consider the following commands and output: typeof(1) ## [1] &quot;double&quot; typeof(1L) ## [1] &quot;integer&quot; typeof(&quot;hello world!&quot;) ## [1] &quot;character&quot; 1.7.2 Other important object types There are other important types of objects in R that are not basic. We will discuss a few. The R Project manual provides additional information about available types. 1.7.2.1 Numeric An object is numeric if it is of type integer or double. In that case, it’s mode is said to be numeric. The is.numeric function tests whether an object can be interpreted as numbers. We can use it to determine whether an object is numeric. Some examples: is.numeric(&quot;hello world!&quot;) ## [1] FALSE is.numeric(1) ## [1] TRUE is.numeric(1L) ## [1] TRUE 1.7.2.2 NULL NULL is a special object to indicate the object is absent. An object having a length of zero is not the same thing as an object being absent. 1.7.2.3 NA A “missing value” occurs when the value of something isn’t known. R uses the special object NA to represent missing value. If you have a missing value, you should represent that value as NA. Note: \"NA\" is not the same thing as NA. 1.7.2.4 Functions A function is an object the performs a certain action or set of actions based on objects it receives from its arguments. 1.7.3 Data structures R operates on data structures. A data structure is simply some sort of “container” that holds certain kinds of information R has 5 basic data structures: vector matrix array data frame list Vectors, matrices, and arrays are homogeneous objects that can only store a single data type at a time. Data frames and lists can store multiple data types. Vectors and lists are considered one-dimensional objects. A list is technically a vector. Vectors of a single type are atomic vectors. (https://cran.r-project.org/doc/manuals/r-release/R-lang.html#List-objects) Matrices and data frames are considered two-dimensional objects. Arrays can be n-dimensional objects. This is summarized in the table below, which is based on a table in the first edition of Hadley Wickham’s Advanced R. dimensionality homogeneous heterogeneous 1d vector list 2d matrix data frame nd array 1.8 Assignment To store a data structure in the computer’s memory we must assign it a name. Data structures can be stored using the assignment operator &lt;- or =. Some comments: In general, both &lt;- and = can be used for assignment. Pressing the “Alt” and “-” keys simultaneously on a PC or Linux machine (Option and - on a Mac) will insert &lt;- into the R console and script files (but not in R Markdown for some reason). &lt;- and = are NOT synonyms, but can be used identically most of the time. It’s safest to use &lt;- for assignment. Once an object has been assigned a name, it can be printed by executing the name of the object or using the print function. 1.8.1 Example In the following code, we compute the mean of a vector and print the result. # compute the mean of 1, 2, ..., 10 and assign the name m m &lt;- mean(1:10) m # print m ## [1] 5.5 print(m) # print m a different way ## [1] 5.5 1.9 Vectors A vector is a single-dimensional set of data of the same type. 1.9.1 Creation The most basic way to create a vector is the c function. The c function combines values into a vector or list. e.g., the following commands create vectors of type numeric, character, and logical, respectively. c(1, 2, 5.3, 6, -2, 4) c(\"one\", \"two\", \"three\") c(TRUE, TRUE, FALSE, TRUE) 1.9.2 Creating patterned vectors R provides a number of functions for creating vectors following certain consistent patterns. The seq (sequence) function is used to create an equidistant series of numeric values. Some examples: seq(1, 10): A sequence of numbers from 1 to 10 in increments of 1. 1:10: A sequence of numbers from 1 to 10 in increments of 1. seq(1, 20, by = 2): A sequence of numbers from 1 to 20 in increments of 2. seq(10, 20, len = 100): A sequence of numbers from 10 to 20 of length 100. The rep (replicate) function can be used to create a vector by replicating values. Some examples: rep(1:3, times = 3): Repeat the sequence 1, 2, 3 three times in a row. rep(c(\"trt1\", \"trt2\", \"trt3\"), times = 1:3): Repeat “trt1” once, “trt2” twice, and “trt3” three times. rep(1:3, each = 3): Repeat each element of the sequence 1, 2, 3 three times. 1.9.3 Example Execute the following commands above in the Console to see what you get. # vector creation c(1, 2, 5.3, 6, -2, 4) c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;) c(TRUE, TRUE, FALSE, TRUE) # sequences of values seq(1, 10) 1:10 seq(1, 20, by = 2) seq(10, 20, len = 100) # replicated values rep(1:3, times = 3) rep(c(&quot;trt1&quot;, &quot;trt2&quot;, &quot;trt3&quot;), times = 1:3) rep(1:3, each = 3) Vectors can be combined into a new object using the c. 1.9.4 Example Execute the following commands in the Console v1 &lt;- 1:5 # create a vector v1 # print the vector ## [1] 1 2 3 4 5 print(v1) ## [1] 1 2 3 4 5 v2 &lt;- c(1, 10, 11) # create a new vector new &lt;- c(v1, v2) # combine and assign the combined vectors new # print the combined vector ## [1] 1 2 3 4 5 1 10 11 1.9.5 Categorical vectors Categorical data should be stored as a factor in R. The factor function takes values that can be coerced to a character and converts them to an object of class factor. Some examples: f1 &lt;- factor(rep(1:6, times = 3)) f1 ## [1] 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 ## Levels: 1 2 3 4 5 6 f2 &lt;- factor(c(&quot;a&quot;, 7, &quot;blue&quot;, &quot;blue&quot;, FALSE)) f2 ## [1] a 7 blue blue FALSE ## Levels: 7 a blue FALSE 1.9.6 Example Create a vector named grp that has two levels: a and b, where the first 7 values are a and the second 4 values are b. 1.9.7 Extracting parts of a vector Subsets of the elements of a vector can be extracted by appending an index vector in square brackets [] to the name of the vector . Let’s create the numeric vector 2, 4, 6, 8, 10, 12, 14, 16. a &lt;- seq(2, 16, by = 2) a ## [1] 2 4 6 8 10 12 14 16 Let’s access the 2nd, 4th, and 6th elements of a. a[c(2, 4, 6)] ## [1] 4 8 12 Let’s access all elements in a EXCEPT the 2nd, 4th, and 6th using the minus (-) sign in front of the index vector. a[-c(2, 4, 6)] ## [1] 2 6 10 14 16 Let’s access all elements in a except elements 3 through 6. a[-(3:6)] ## [1] 2 4 14 16 1.10 Helpful functions 1.10.1 General functions Some general functions commonly used to describe data objects: length(x): length of x sum(x): sum elements in x mean(x): sample mean of elements in x var(x): sample variance of elements in x sd(x): sample standard deviation of elements in x range(x): range (minimum and maximum) of elements in x log(x): (natural) logarithm of elements in x summary(x): a summary of x. Output changes depending on the class of x. str(x): provides information about the structure of x. Usually, the class of the object and some information about its size. 1.10.2 Example Run the following commands in the Console: x &lt;- rexp(100) # sample 100 iid values from an Exponential(1) distribution length(x) # length of x sum(x) # sum of x mean(x) # sample mean of x var(x) # sample variance of x sd(x) # sample standard deviation of x range(x) # range of x log(x) # logarithm of x summary(x) # summary of x str(x) # structure of x 1.10.3 Functions related to statistical distributions Suppose that a random variable \\(X\\) has the dist distribution: p[dist](q, ...): returns the cdf of \\(X\\) evaluated at q, i.e., \\(p=P(X\\leq q)\\). q[dist](p, ...): returns the inverse cdf (or quantile function) of \\(X\\) evaluated at \\(p\\), i.e., \\(q = \\inf\\{x: P(X\\leq x) \\geq p\\}\\). d[dist](x, ...): returns the mass or density of \\(X\\) evaluated at \\(x\\) (depending on whether it’s discrete or continuous). r[dist](n, ...): returns an i.i.d. random sample of size n having the same distribution as \\(X\\). The ... indicates that additional arguments describing the parameters of the distribution may be required. 1.10.4 Example Execute the following commands in R to see the output. What is each command doing? pnorm(1.96, mean = 0, sd = 1) qunif(0.6, min = 0, max = 1) dbinom(2, size = 20, prob = .2) dexp(1, rate = 2) rchisq(100, df = 5) pnorm(1.96, mean = 0, sd = 1) returns the probability that a standard normal random variable is less than or equal to 1.96, i.e., \\(P(X \\leq 1.96)\\). qunif(0.6, min = 0, max = 1) returns the value \\(x\\) such that \\(P(X\\leq x) = 0.6\\) for a uniform random variable on the interval \\([0, 1]\\). dbinom(2, size = 20, prob = .2) returns the probability that \\(P(X=2)\\) for \\(X∼\\textrm{Binom}(n=20,\\pi=0.2)\\). dexp(1, rate = 2) evaluates the density of an exponential random variable with mean = 1/2 at \\(x=1\\). rchisq(100, df = 5) returns a sample of 100 observations from a chi-squared random variable with 5 degrees of freedom. 1.11 Data Frames Data frames are two-dimensional data objects. Each column of a data frame is a vector (or variable) of possibly different data types. This is a fundamental data structure used by most of R’s modeling software. In general, I recommend tidy data, which means that each variable forms a column of the data frame, and each observation forms a row. 1.11.1 Creation Data frames are created by passing vectors into the data.frame function. The names of the columns in the data frame are the names of the vectors you give the data.frame function. Consider the following simple example. d &lt;- c(1, 2, 3, 4) e &lt;- c(&quot;red&quot;, &quot;white&quot;, &quot;blue&quot;, NA) f &lt;- c(TRUE, TRUE, TRUE, FALSE) df &lt;- data.frame(d,e,f) df ## d e f ## 1 1 red TRUE ## 2 2 white TRUE ## 3 3 blue TRUE ## 4 4 &lt;NA&gt; FALSE The columns of a data frame can be renamed using the names function on the data frame. names(df) &lt;- c(&quot;ID&quot;, &quot;Color&quot;, &quot;Passed&quot;) df ## ID Color Passed ## 1 1 red TRUE ## 2 2 white TRUE ## 3 3 blue TRUE ## 4 4 &lt;NA&gt; FALSE The columns of a data frame can be named when you are first creating the data frame by using name = for each vector of data. df2 &lt;- data.frame(ID = d, Color = e, Passed = f) df2 ## ID Color Passed ## 1 1 red TRUE ## 2 2 white TRUE ## 3 3 blue TRUE ## 4 4 &lt;NA&gt; FALSE 1.11.2 Extracting parts of a data frame The column vectors of a data frame may be extracted using $ and specifying the name of the desired vector. df$Color would access the Color column of data frame df. Part of a data frame can also be extracted by thinking of at as a general matrix and specifying the desired rows or columns in square brackets after the object name. For example, if we had a data frame named df: df[1,] would access the first row of df. df[1:2,] would access the first two rows of df. df[,2] would access the second column of df. df[1:2, 2:3] would access the information in rows 1 and 2 of columns 2 and 3 of df. If you need to select multiple columns of a data frame by name, you can pass a character vector with column names in the column position of []. df[, c(\"Color\", \"Passed\")] would extract the Color and Passed columns of df. ### Example {.example} Execute the following commands in the Console: df3 &lt;- data.frame(numbers = 1:5, characters = letters[1:5], logicals = c(TRUE, TRUE, FALSE, TRUE, FALSE)) df3 # print df df3$logicals # access the logicals vector of df3 df3[1, ] # access the first column of df3 df3[, 3] # access the third column of df3 df3[, 2:3] # access the column 2 and 3 of df3 df3[, c(&quot;numbers&quot;, &quot;logicals&quot;)] # access the numbers and logical columns of df3 Students often can work more conveniently with vectors, so it is sometimes desirable to access a part of a data frame and assign it a new name for later use. For example, to access the ID column of df2 and assign it the name newID, we could execute newID &lt;- df2$ID. 1.11.3 Importing Data The read.table function imports data from file into R as a data frame. Usage: read.table(file, header = TRUE, sep = \",\") file is the file path and name of the file you want to import into R. If you don’t know the file path, set file = file.choose() will bring up a dialog box asking you to locate the file you want to import. header specifies whether the data file has a header (variable labels for each column of data in the first row of the data file). If you don’t specify this option in R or use header = FALSE, then R will assume the file doesn’t have any headings. header = TRUE tells R to read in the data as a data frame with column names taken from the first row of the data file. sep specifies the delimiter separating elements in the file. If each column of data in the file is separated by a space, then use sep = \" \" If each column of data in the file is separated by a comma, then use sep = \",\" If each column of data in the file is separated by a tab, then use sep = \"\\t\". Here is an example reading a csv (comma separated file) with a header: dtf &lt;- read.table(file = &quot;https://raw.githubusercontent.com/jfrench/DataWrangleViz/master/data/covid_dec4.csv&quot;, header = TRUE, sep = &quot;,&quot;) str(dtf) ## &#39;data.frame&#39;:\t50 obs. of 7 variables: ## $ state_name: chr &quot;Alabama&quot; &quot;Alaska&quot; &quot;Arizona&quot; &quot;Arkansas&quot; ... ## $ state_abb : chr &quot;AL&quot; &quot;AK&quot; &quot;AZ&quot; &quot;AR&quot; ... ## $ deaths : int 3831 142 6885 2586 19582 2724 5146 782 19236 9725 ... ## $ population: num 387000 96500 498000 238000 2815000 ... ## $ income : int 25734 35455 29348 25359 31086 35053 37299 32928 27107 28838 ... ## $ hs : num 82.1 91 85.6 82.9 80.7 89.7 88.6 87.7 85.5 84.3 ... ## $ bs : num 21.9 27.9 25.9 19.5 30.1 36.4 35.5 27.8 25.8 27.3 ... Note that the read_table function in the readr package and the fread function in the data.table package are perhaps better ways of reading in tabular data and use similar syntax. 1.12 Logical statements 1.12.1 Basic comparisons Sometimes we need to know if the elements of an object satisfy certain conditions. This can be determined using the logical operators &lt;, &lt;=, &gt;, &gt;=, ==, !=. == means equal to. != means NOT equal to. 1.12.2 Example Execute the following commands in R and see what you get. What is each statement performing? # a &lt;- seq(2, 16, by = 2) # creating the vector a a a &gt; 10 a &lt;= 4 a == 10 a != 10 1.12.3 And and Or statements More complicated logical statements can be made using &amp; and |. &amp; means “and” | means “or” 1.12.4 Example Execute the following commands in R and see what you get. (a &gt; 6) &amp; (a &lt;= 10) (a &lt;= 4) | (a &gt;= 12) 1.13 Subsetting with logical statements Logical statements can be used to return parts of an object satisfying the appropriate criteria. Specifically, we pass logical statements within the square brackets used to access part of a data structure. 1.13.1 Example Execute the following code: a a &lt; 6 a[a &lt; 6] a == 10 a[a == 10] (a &lt; 6) | ( a == 10) a[(a &lt; 6) | ( a == 10)] 1.14 Ecosystem debate We will typically work with base R, which are commands and functions R offers by default. The tidyverse (www.tidyverse.org) is a collection of R packages that provides a unified framework for data manipulation and visualization. Since this course focuses more on modeling than data manipulation, I will typically focus on approaches in base R. I will use functions from the tidyverse when it greatly simplifies analysis, data manipulation, or visualization. "],
["data-exploration-a-k-a-exploratory-data-analysis.html", "Chapter 2 Data exploration (a.k.a., exploratory data analysis) 2.1 Data analysis process 2.2 Data exploration 2.3 Kidney Example 2.4 Visualizing the data with base graphics 2.5 A ggplot2 scatter plot 2.6 Summary of data exploration", " Chapter 2 Data exploration (a.k.a., exploratory data analysis) Based on Chapter 1 of LMWR2, Chapter 1 of ALR4 2.1 Data analysis process Define a question of interest. Collect relevant data. Analyze the data. Interpret your analysis. Make a decision. “The formulation of a problem is often more essential than its solution, which may be merely a matter of mathematical or experimental skill” - Albert Einstein 2.1.1 Problem Formulation Understand the physical background. Statisticians often work in collaboration with others and need to understand something about the subject area. Understand the objective. What are your goals? Make sure you know what the client wants. Put the problem into statistical terms. This is often the most challenging step and where irreparable errors are sometimes made. That a statistical method can read in and process the data is not enough. The results of an inapt analysis may be meaningless. 2.1.2 Data collection Data collection: * How the data were collected has a crucial impact on what conclusions can be made. * Are the data observational or experimental? * Are the data a sample of convenience or were they obtained via a designed sample survey? * Is there nonresponse bias? * The data you do not see may be just as important as the data you do see. * Are there missing values? * This is a common problem that is troublesome and time consuming to handle. * How are the data coded? How are the qualitative variables represented? * What are the units of measurement? * Beware of data entry errors and other corruption of the data. * Perform some data sanity checks. 2.2 Data exploration An initial exploration of the data should be performed prior to any formal analysis or modeling. Initial data analysis should consist of numerical summaries and appropriate plots. 2.2.1 Numerical summaries of data Statistics can be used to numerically summarize aspects of the data: mean standard deviation (SD) maximum and minimum correlation other measures, as appropriate 2.2.2 Visual summaries of data Plots can provide a useful visual summary of the data. For one numerical variable: boxplots, histograms, density plots, etc. For two numerical variables: scatterplots. For three or more variables, construct interactive and dynamic graphics. For one categorial variable: bar charts Good graphics are essential in data analysis. They help us avoid mistakes. They help us decide on a model. They help communicate the results of our analysis. Graphics can be more convincing than text at times. 2.2.3 What to look for When summarizing the data, look for: outliers data-entry errors skewness unusual distributions patterns or structure 2.3 Kidney Example The National Institute of Diabetes and Digestive and Kidney Diseases conducted a study on 768 adult female Pima Indians living near Phoenix. The following variables were recorded: * pregnant - number of times pregnant * glucose - plasma glucose concentration at 2 hours in an oral glucose tolerance test * diastolic - diastolic blood pressure (mm Hg) * triceps - triceps skin fold thickness (mm) * insulin - 2-hour serum insulin (mu U/ml) * bmi - body mass index (weight in kg/(height in m2)) * diabetes - diabetes pedigree function * age - age (years) * test - test whether the patient showed signs of diabetes (coded zero if negative, one if positive). The data may be obtained from the UCI Repository of machine learning databases at https://archive.ics.uci.edu/ml. Let’s load and examine the structure of the data data(pima, package = &quot;faraway&quot;) str(pima) # structure ## &#39;data.frame&#39;:\t768 obs. of 9 variables: ## $ pregnant : int 6 1 8 1 0 5 3 10 2 8 ... ## $ glucose : int 148 85 183 89 137 116 78 115 197 125 ... ## $ diastolic: int 72 66 64 66 40 74 50 0 70 96 ... ## $ triceps : int 35 29 0 23 35 0 32 0 45 0 ... ## $ insulin : int 0 0 0 94 168 0 88 0 543 0 ... ## $ bmi : num 33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 0 ... ## $ diabetes : num 0.627 0.351 0.672 0.167 2.288 ... ## $ age : int 50 31 32 21 33 30 26 29 53 54 ... ## $ test : int 1 0 1 0 1 0 1 0 1 1 ... head(pima) # first six rows ## pregnant glucose diastolic triceps insulin bmi diabetes age test ## 1 6 148 72 35 0 33.6 0.627 50 1 ## 2 1 85 66 29 0 26.6 0.351 31 0 ## 3 8 183 64 0 0 23.3 0.672 32 1 ## 4 1 89 66 23 94 28.1 0.167 21 0 ## 5 0 137 40 35 168 43.1 2.288 33 1 ## 6 5 116 74 0 0 25.6 0.201 30 0 tail(pima) # last six rows ## pregnant glucose diastolic triceps insulin bmi diabetes age test ## 763 9 89 62 0 0 22.5 0.142 33 0 ## 764 10 101 76 48 180 32.9 0.171 63 0 ## 765 2 122 70 27 0 36.8 0.340 27 0 ## 766 5 121 72 23 112 26.2 0.245 30 0 ## 767 1 126 60 0 0 30.1 0.349 47 1 ## 768 1 93 70 31 0 30.4 0.315 23 0 2.3.1 Numerically summarizing the data The summary command is a useful way to numerically summarize a data frame. The summary function will compute the minimum, 0.25 quantile, mean, median, 0.75 quantile, and maximum of a numeric variable. The summary function will count the number of values of each level of a factor variable. Let’s summarize the pima data frame. summary(pima) ## pregnant glucose diastolic triceps ## Min. : 0.000 Min. : 0.0 Min. : 0.00 Min. : 0.00 ## 1st Qu.: 1.000 1st Qu.: 99.0 1st Qu.: 62.00 1st Qu.: 0.00 ## Median : 3.000 Median :117.0 Median : 72.00 Median :23.00 ## Mean : 3.845 Mean :120.9 Mean : 69.11 Mean :20.54 ## 3rd Qu.: 6.000 3rd Qu.:140.2 3rd Qu.: 80.00 3rd Qu.:32.00 ## Max. :17.000 Max. :199.0 Max. :122.00 Max. :99.00 ## insulin bmi diabetes age ## Min. : 0.0 Min. : 0.00 Min. :0.0780 Min. :21.00 ## 1st Qu.: 0.0 1st Qu.:27.30 1st Qu.:0.2437 1st Qu.:24.00 ## Median : 30.5 Median :32.00 Median :0.3725 Median :29.00 ## Mean : 79.8 Mean :31.99 Mean :0.4719 Mean :33.24 ## 3rd Qu.:127.2 3rd Qu.:36.60 3rd Qu.:0.6262 3rd Qu.:41.00 ## Max. :846.0 Max. :67.10 Max. :2.4200 Max. :81.00 ## test ## Min. :0.000 ## 1st Qu.:0.000 ## Median :0.000 ## Mean :0.349 ## 3rd Qu.:1.000 ## Max. :1.000 2.3.2 Cleaning the data Cleaning data involves finding and correcting data quality issues. Some odd things about the pima data The minimum blood pressue is zero. That’s generally an indication of a health problem. The test variable appears to be numerical but should be a categorical variable. Many other variables have unusual zeros. Look for anything unusual or unexpected, perhaps indicating a data-entry error. Let’s look at the sorted diastolic values. sort(pima$diastolic) ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [19] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 ## [37] 30 30 38 40 44 44 44 44 46 46 48 48 48 48 48 50 50 50 ## [55] 50 50 50 50 50 50 50 50 50 50 52 52 52 52 52 52 52 52 ## [73] 52 52 52 54 54 54 54 54 54 54 54 54 54 54 55 55 56 56 ## [91] 56 56 56 56 56 56 56 56 56 56 58 58 58 58 58 58 58 58 ## [109] 58 58 58 58 58 58 58 58 58 58 58 58 58 60 60 60 60 60 ## [127] 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 ## [145] 60 60 60 60 60 60 60 60 60 60 60 60 60 60 61 62 62 62 ## [163] 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 ## [181] 62 62 62 62 62 62 62 62 62 62 62 62 62 64 64 64 64 64 ## [199] 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 ## [217] 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 ## [235] 64 64 65 65 65 65 65 65 65 66 66 66 66 66 66 66 66 66 ## [253] 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 ## [271] 66 66 66 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 ## [289] 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 ## [307] 68 68 68 68 68 68 68 68 68 68 68 68 70 70 70 70 70 70 ## [325] 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 ## [343] 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 ## [361] 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 72 72 72 ## [379] 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 ## [397] 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 ## [415] 72 72 72 72 72 74 74 74 74 74 74 74 74 74 74 74 74 74 ## [433] 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 ## [451] 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 ## [469] 74 74 74 75 75 75 75 75 75 75 75 76 76 76 76 76 76 76 ## [487] 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 ## [505] 76 76 76 76 76 76 76 76 76 76 76 76 76 76 78 78 78 78 ## [523] 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 ## [541] 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 ## [559] 78 78 78 78 78 80 80 80 80 80 80 80 80 80 80 80 80 80 ## [577] 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 ## [595] 80 80 80 80 80 80 80 80 80 82 82 82 82 82 82 82 82 82 ## [613] 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 ## [631] 82 82 82 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 ## [649] 84 84 84 84 84 84 84 84 85 85 85 85 85 85 86 86 86 86 ## [667] 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 88 ## [685] 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 ## [703] 88 88 88 88 88 88 90 90 90 90 90 90 90 90 90 90 90 90 ## [721] 90 90 90 90 90 90 90 90 90 90 92 92 92 92 92 92 92 92 ## [739] 94 94 94 94 94 94 95 96 96 96 96 98 98 98 100 100 100 102 ## [757] 104 104 106 106 106 108 108 110 110 110 114 122 The first 35 values of diastolic are zero. That’s a problem. * It seems that 0 was used in place of a missing value. * This is very bad since 0 is a real number and this problem may be overlooked, which can lead to faulty analysis! * This is why we must check our data carefully for things that don’t make sense. The value for missing data in R is NA. Several variables share this problem. Let’s set the 0s that should be missing values to NA. pima$diastolic[pima$diastolic == 0] &lt;- NA pima$glucose[pima$glucose == 0] &lt;- NA pima$triceps[pima$triceps == 0] &lt;- NA pima$insulin[pima$insulin == 0] &lt;- NA pima$bmi[pima$bmi == 0] &lt;- NA The test variable is a categorical variable, not numerical. R thinks the test variable is numeric. In R, a categorical variable is a factor. We need to convert the test variable to a factor. Let’s convert test to a factor. pima$test &lt;- factor(pima$test) summary(pima$test) ## 0 1 ## 500 268 500 of the cases were negative and 268 were positive. We can provide more descriptive labels using the levels function. levels(pima$test) &lt;- c(&quot;negative&quot;,&quot;positive&quot;) 2.4 Visualizing the data with base graphics 2.4.1 Histograms The hist command can be used create a histogram of a numerical vector. The labels of the plot can be customized using the xlab and ylab arguments. The main title of the plot can be customized using the main argument. Here is a slightly customized histogram of diastolic blood pressure. hist(pima$dias, xlab = &quot;diastolic blood pressure&quot; , main=&quot;&quot;) The histogram is approximately bell-shaped and centered around 70. We can change the number of breaks in the histogram by specifying the breaks argument of the hist function. Consider how the plot changes below. hist(pima$dias, xlab = &quot;diastolic blood pressure&quot;, main = &quot;&quot;, breaks = 20) 2.4.2 Density plots Many people prefer the density plot over the histogram because the histogram is more sensitive to its options. A density plot is essentially a smoothed version of a histogram. * It isn’t as blocky. * It sometimes has weird things happen at the boundaries. The plot and density function can be combined to construct a density plot. plot(density(pima$diastolic, na.rm=TRUE), main = &quot;&quot;) In the example above, we have to specify na.rm = TRUE so that the density is only computed using the non-missing values. 2.4.3 Scatter plots A scatter plot of the sorted numerical values versus their index can be used to identify outliers and see whether the data has many repeated values. plot(sort(pima$diastolic), ylab = &quot;sorted diastolic bp&quot;) The flat spots in the plot above show that the diastolic variable has mean repeated values. 2.4.4 Bivariate scatter plots Bivariate scatter plots can be used to idenify the relationship between two numerical variables. A scatter plot of diabetes vs diastolic blood pressure. plot(diabetes ~ diastolic, data = pima) There is no clear pattern in the points, so it’s difficult to claim a relationship between the two variables. 2.4.5 Bivariate boxplots A parallel boxplot of diabetes score versus test result. plot(diabetes ~ test, data = pima) The median diabetes score seems to be a bit higher for positive tests in comparison to the negative tests. 2.4.6 Multiple plots in one figure The par function can be used to construct multiple plots in one figure. The mfrow argument can be used to specify the number of rows and columns of plots you need. A 1 by 2 set of plots is shown below. par(mfrow = c(1, 2)) plot(diabetes ~ diastolic, data = pima) plot(diabetes ~ test, data = pima) ## Visualizing the data with ggplot2 The plots we have just created are using the base graphics system in R. * These are very fast, simple, and professional. A fancier alternative is to construct plots using the ggplot2 package. In its simplest form, ggplot2 requires you to provide: A ggplot object that includes the data frame holding the data. A mapping arguments that specifies the plot aesthetics (essentially, how the data that will be used in the plot). A geometry object that specifies how the aesthetics are used in a plot. 2.4.7 A ggplot2 histogram library(ggplot2) ## Warning: package &#39;ggplot2&#39; was built under R version 4.0.3 ggpima &lt;- ggplot(pima) ggpima + geom_histogram(aes(x=diastolic)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 35 rows containing non-finite values (stat_bin). 2.4.8 A ggplot2 density plot ggpima + geom_density(aes(x = diastolic)) ## Warning: Removed 35 rows containing non-finite values (stat_density). 2.5 A ggplot2 scatter plot ggpima + geom_point(aes(x = diastolic, y = diabetes)) ## Warning: Removed 35 rows containing missing values (geom_point). 2.5.1 Customizing ggplot2 plots We can customize our ggplots in numerous ways. Some examples: * Change the point shapes based on a categorical variable.. * Change the location and orientation of the legend. ggpima + geom_point(aes(x = diastolic, y = diabetes, shape = test)) + theme(legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot;) ## Warning: Removed 35 rows containing missing values (geom_point). 2.5.2 Facetting in ggplot2 Facetting creates separate plots (facets) of a data frame based on one or more facetting variables. Below, we facet the data by the test result. ggpima + geom_point(aes(x = diastolic, y = diabetes)) + facet_grid(~ test) ## Warning: Removed 35 rows containing missing values (geom_point). 2.5.3 Summary of ggplot2 Create a ggplot object using the ggplot function. Specify the data frame the data is contained in (e.g., the data frame is pima). Specify the geometry for the plot (the kind of plot you want to produce) Specify the aesthetics using aes. The aesthetic specifies what you see, such as position in the \\(x\\) or \\(y\\) direction or aspects such as shape or color. The aesthetic can be specifed in the geometry, or if you have consistent aesthetics across multiple geometries, in the `ggplot statement. The advantage of ggplot2 is more apparent in producing complex plots involving more than two variables. A theme specifies options for the appearance of the plot. We specified where the legend should appear in one plot and to use more than one panel (facets) in another. 2.6 Summary of data exploration Data exploration helps us to understand the data, identify problems or unusual features of our data, decide on a modeling approach for the data, etc. You should use both numerical and graphical summaries of data prior to modeling the data. "],
["linear-models-and-regression.html", "Chapter 3 Linear models and regression 3.1 Regression models 3.2 Common types of regression models 3.3 Basic assumptions of linear models 3.4 Goals of regression 3.5 Scatter plots and linear regression", " Chapter 3 Linear models and regression 3.1 Regression models Regression models are used to model the relationship between: a single variable \\(Y\\), called the response, outcome, output, or dependent variable. one or more predictor, input, independent, explanatory, or feature variables. Note: the descriptions of independent and dependent variables are vague and are best avoided. A distinction is sometimes made between regression and classification models. In that case: Regression models attempt to predict the numerical response. Classification models attempt to predict the category level a response will have. A linear model is a regression model in which the regression coefficients (to be discussed later) enter the model linearly. A linear model is just a specific type of regression model. 3.2 Common types of regression models Simple regression model: a regression model with one constant predictor and one non-constant predictor. Multiple regression model: a regression model with more than one non-constant predictor. Multivariate regression model: a regression model with more than one response variable. Linear regression model: a regression model in which the regression coefficients enter the model linearly. Analysis of variance (ANOVA) model: a linear regression model with one or more categorical predictors. Analysis of covariance (ANCOVA): a linear regression model with a quantitative predictor and a categorical predictor. Generalized linear model (GLM): a type of “generalized” regression model when the responses do not come from a normal distribution. 3.3 Basic assumptions of linear models The most basic assumptions of linear regression models: The response variable \\(Y\\) is continuous. The regression coefficients enter the model linearly. Predictors can be continuous, discrete, or categorical. 3.4 Goals of regression Prediction of future or unseen responses given specified values of the predictors. Assessments of the effect of, or relationship between, explanatory variables and the response. We would like to infer causal relationships if possible. Be clear of your objective! Your choice of analysis may differ depending on the objective. There is no such thing as a “true model” for real data. We want to find a model that adequately describes the relationship between the response and relevant predictor variables, allows us to make good predictions, infer causality, etc. 3.5 Scatter plots and linear regression Scatter plots are a convenient way to study the potential relationship between a single response and a single predictor variable. 3.5.1 Height inheritability Karl Pearson (1857-1936) organized the collection of \\(n=1375\\) heights of mothers in the United Kingdom under the age of 65 and one of their adult daughters over the age of 18. These data are available in the Heights data set in the alr4 package. We are interested in the inheritance from the mother to the daughter, so the mother’s height (mheight) is used as the predictor variable and the daughter’s height (dheight) is used as the response variable. Questions of interest: Do taller mothers tend to have taller daughters Do shorter mothers tend to have shorter daughters? data(Heights, package = &quot;alr4&quot;) str(Heights) ## &#39;data.frame&#39;:\t1375 obs. of 2 variables: ## $ mheight: num 59.7 58.2 60.6 60.7 61.8 55.5 55.4 56.8 57.5 57.3 ... ## $ dheight: num 55.1 56.5 56 56.8 56 57.9 57.1 57.6 57.2 57.1 ... plot(dheight ~ mheight, data = Heights, xlab = &quot;mother&#39;s height (in)&quot;, ylab = &quot;daughter&#39;s height (in)&quot;, xlim = c(55, 75), ylim = c(55, 75)) There seems to be a clear trend between mother’s heights and daughter’s heights. The taller the mother, the taller the daughter tends to be. 3.5.2 Predicting snowfall The ftcollinssnow data set in the alr4 package measures late (September 1st until December 31st) and early (January 1st to June 30th) season snowfall for Fort Collins, CO between Late 1900 and Early 1993. Question of interest: Can late season snowfall predict snowfall in the early part of the next year? data(&quot;ftcollinssnow&quot;, package = &quot;alr4&quot;) # load data str(ftcollinssnow) # examine structure ## &#39;data.frame&#39;:\t93 obs. of 3 variables: ## $ YR1 : int 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 ... ## $ Early: num 3 15.8 13.1 4 1 10.5 27.5 7 28.7 19.9 ... ## $ Late : num 44.5 12.5 36.8 7.6 28.7 28.3 49.7 15.1 51.2 5.9 ... plot(Late ~ Early, data = ftcollinssnow) # plot data # add &quot;line of best fit&quot; abline(lm(Late ~ Early, data = ftcollinssnow), lty = 2) # sample mean line abline(mean(ftcollinssnow$Late), 0) A plot of the snowfall data for the two time periods suggest that this relationship is weak or they may be uncorrelated. * The dashed line indicates the “linear of best fit” , while the solid line indicates the average of the Late snowfall. 3.5.3 Turkey growth Pens of turkeys were fed the same diet, except that each pen was supplemented with a Dose of amino acid methionine as a percentage of the total diet of the birds. The amino acid methionine was provided using three different Sources (one standard and two experimental). The Weight gain (g) of the turkeys was measured. These data are available in the turkey data in the alr4 package. Questions of interest: Is there a relationship between weight gain of the turkeys and the dose amount? If so, is the relationship linear? Does the source of the methionine impact the weight gain of the turkeys? Consider a plot of the average Weight gain (g) of the turkeys as a function of the Dose amount (% of diet), separating the groups by the Source of the methionine. data(turkey, package = &quot;alr4&quot;) str(turkey) ## &#39;data.frame&#39;:\t13 obs. of 5 variables: ## $ A : num 0 0.04 0.1 0.16 0.28 0.04 0.1 0.16 0.28 0.04 ... ## $ Gain: num 623 680 721 750 789 ... ## $ S : int 1 1 1 1 1 2 2 2 2 3 ... ## $ m : int 10 5 5 5 5 5 5 5 5 5 ... ## $ SD : num 19.46 7.19 21.45 17.49 14.67 ... summary(turkey) # the source factor (S) is not a factor ## A Gain S m ## Min. :0.0000 Min. :623.0 Min. :1.000 Min. : 5.000 ## 1st Qu.:0.0400 1st Qu.:680.2 1st Qu.:1.000 1st Qu.: 5.000 ## Median :0.1000 Median :721.4 Median :2.000 Median : 5.000 ## Mean :0.1338 Mean :720.4 Mean :1.923 Mean : 5.385 ## 3rd Qu.:0.1600 3rd Qu.:750.4 3rd Qu.:3.000 3rd Qu.: 5.000 ## Max. :0.2800 Max. :794.0 Max. :3.000 Max. :10.000 ## SD ## Min. : 7.19 ## 1st Qu.:14.67 ## Median :17.71 ## Mean :17.68 ## 3rd Qu.:21.45 ## Max. :26.51 turkey$S = factor(turkey$S) levels(turkey$S) &lt;- c(&quot;control&quot;, &quot;new source a&quot;, &quot;new source b&quot;) names(turkey) &lt;- c(&quot;Dose&quot;, &quot;Gain&quot;, &quot;Source&quot;, &quot;Replications&quot;, &quot;SD&quot;) # rename variables # create turkey data ggplot library(ggplot2) # load ggplot2 package gg_turkey &lt;- ggplot(turkey, mapping = aes(x = Dose, y = Gain, color = Source, shape = Source)) gg_turkey + geom_point() + geom_line() Weight gain increases with dose amount, but doesn’t appear to be linear. The amino acid source may slightly affect the growth trajectory of the turkeys. An alternative version of the previous plot using the lattice package library(lattice) # load lattice package xyplot(Gain ~ Dose, data = turkey, groups = Source, auto.key = TRUE, type = &quot;b&quot;) "],
["review-of-probability-random-variables-and-random-vectors.html", "Chapter 4 Review of probability, random variables, and random vectors 4.1 Probability Basics 4.2 Independence 4.3 Random Variables 4.4 Multivariate distributions 4.5 Joint of continuous RV 4.6 Covariance 4.7 Properties of Variance and Covariance 4.8 Independence 4.9 Properties of random vectors 4.10 Properties of random vectors 4.11 Important Properties 4.12 Important Properties 4.13 Important Properties 4.14 Multivariate normal (Gaussian) distribution 4.15 Properties 4.16 Example 4.17 Problem 1 4.18 Problem 2 4.19 Problem 3 4.20 Problem 4 4.21 Problem 5 4.22 Problem 6 4.23 Problem 7 4.24 Matrix Differentiation 4.25 Matrix Differentiation 1 4.26 Matrix Differentiation 1 (Proof) 4.27 Matrix Differentiation 2 4.28 Matrix Differentiation 2 (Proof) 4.29 Matrix Differentiation 3 4.30 Matrix Differentiation 3 (Proof) 4.31 Matrix Differentiation 3.5 4.32 Matrix Differentiation 4 4.33 Matrix Differentiation 4.5", " Chapter 4 Review of probability, random variables, and random vectors 4.1 Probability Basics The sample space \\(\\Omega\\) is the set of possible outcomes of an experiment. Points \\(\\omega\\) in \\(\\Omega\\) are called sample outcomes, realizations, or elements. A set is a (possibly empty) collection of elements. We usually denote sets with as something like \\(\\{\\omega_1, \\omega_2, \\ldots\\}\\), where the \\(\\omega_i\\) are elements of \\(\\Omega\\). Set \\(A\\) is a subset of set \\(B\\) if every element of \\(A\\) is an element of \\(B\\). This is denoted as \\(A \\subseteq B\\), meaning that \\(A\\) is a subset of \\(B\\). Subsets of \\(\\Omega\\) are events. The null set or empty set, \\(\\emptyset\\), is the set with no elements \\(\\{\\}\\). The empty set is a subset of any other set. A function \\(P\\) that assigns a real number \\(P(A)\\) to every event \\(A\\) is a probability distribution if it satisfies three properties: \\(P(A)\\geq 0\\) for all \\(A\\in \\Omega\\) \\(P(\\Omega)=P(\\omega \\in \\Omega) = 1\\) If \\(A_1, A_2, \\ldots\\) are disjoint, then \\(P\\left(\\bigcup_{i=1}^\\infty A_i \\right)=\\sum_{i=1}^\\infty P(A_i)\\). 4.2 Independence A set of events \\(\\{A_i:i\\in I\\}\\) is independent if \\[P\\left(\\cap_{i\\in J} A_i \\right)=\\prod_{i\\in J} P(A_i ) \\] for every finite subset \\(J\\) of \\(I\\). 4.3 Random Variables A random variable \\(Y\\) is a mapping/function \\[Y:\\Omega\\to\\mathbb{R}\\] that assigns a real number \\(Y(\\omega)\\) to each outcome \\(\\omega\\). The cumulative distribution function (CDF) of \\(Y\\), \\(F_Y\\), is a function \\(F_Y:\\mathbb{R}\\to [0,1]\\) defined by \\[F_Y (y)=P(Y \\leq y).\\] The subscript of \\(F\\) indicates which random variable the CDF describes. E.g., \\(F_X\\) denotes the CDF of the random variable \\(X\\) and \\(F_Y\\) denotes the CDF of the random variable \\(Y\\). The support of \\(Y\\), \\(\\mathcal{S}\\), is the smallest set such that \\(P(Y\\in \\mathcal{S})=1\\). 4.3.1 Discrete random variables \\(Y\\) is a discrete random variable if it takes countably many values \\(\\{y_1, y_2, \\dots \\} = \\mathcal{S}\\). The probability mass function (pmf) for \\(Y\\) is \\(f_Y (y)=P(Y=y)\\), where \\(y\\in \\mathbb{R}\\), and must have the following properties: \\(0 \\leq f_Y(y) \\leq 1\\). \\(\\sum_{y\\in \\mathcal{S}} f_Y(y) = 1\\). Additionally, the following is true: \\(F_Y(c) = P(Y \\leq c) = \\sum_{y\\in \\mathcal{S}:y \\leq c} f_Y(y)\\). \\(P(Y \\in A) = \\sum_{y \\in A} f_Y(y)\\) for some event \\(A\\). \\(P(a \\leq Y \\leq b) = \\sum_{y\\in\\mathcal{S}:a\\leq y\\leq b} f_Y(y)\\). The expected value, mean, or first moment of \\(Y\\) is defined as \\[E(Y) = \\sum_{y\\in \\mathcal{S}} y f_Y(y),\\] assuming the sum is well-defined. The variance of \\(Y\\) is defined as \\[var(Y)=E(Y-E(Y))^2== \\sum_{y\\in \\mathcal{S}} (y - E(Y))^2 f_Y(y).\\] The standard deviation of Y is \\[SD(Y)=\\sqrt{var(Y) }\\]. 4.3.2 Bernoulli random variables A random variable \\(Y\\sim \\mathsf{Bernoulli}(\\pi)\\) if \\(\\mathcal{S} = {0, 1}\\) and \\(P(Y = 1) = \\pi\\), where \\(\\pi\\in (0,1)\\). The pmf of a Bernoulli random variable is \\[f_Y(y) = \\pi^y (1-\\pi)^{(1-y)}.\\] Determine \\(E(Y)\\) and \\(var(Y)\\). 4.3.3 Continuous random variables \\(Y\\) is a continuous random variable if there exists a function \\(f_Y (y)\\) such that: \\(f_Y (y)\\geq 0\\) for all \\(y\\), \\(\\int_{-\\infty}^\\infty f_Y (y) dy = 1\\), and for \\(a\\leq b\\), \\(P(a&lt;Y&lt;b)=\\int_a^b f_Y (y) dy\\). The function \\(f_Y\\) is called the probability density function (pdf). Additionally, \\(F_Y (y)=\\int_{-\\infty}^y f_Y (y) dy\\) and \\(f_Y (y)=F&#39;_Y(y)\\) for any point \\(y\\) at which \\(F_Y\\) is differentiable. The expected value of a continuous random variables \\(Y\\) is defined as \\[E(Y)= \\int_{-\\infty}^{\\infty} y f_Y(y) dy = \\int_{y\\in\\mathcal{S}} y f_Y(y).\\] assuming integral are well-defined. The variance of a continuous random variable \\(Y\\) is defined by \\[var(Y)=E(Y-E(Y))^2=\\int_{-\\infty}^{\\infty} (y - E(Y))^2 f_Y(y) dy = \\int_{y\\in\\mathcal{S}} (y - E(Y))^2 f_Y(y).\\] The standard deviation of Y is \\[SD(Y)=\\sqrt{var(Y) }\\]. 4.3.4 Useful facts for simple random variable transformations Let \\(Y\\) be a random variable and \\(a\\in\\mathbb{R}\\) be a constant. Then: * \\(E(aY)=aE(Y)\\) * \\(E(a+Y)=a+E(Y)\\) * \\(var(aY)=a^2 var(Y)\\) * \\(var(a+Y)=var(Y)\\) 4.4 Multivariate distributions 4.4.1 Basic properties Let \\(Y_1,Y_2,\\ldots,Y_n\\) denote \\(n\\) random variables with support \\(\\mathcal{S}_1,\\mathcal{S}_2,\\ldots,\\mathcal{S}_n\\), respectively. If the random variables are jointly (all) discrete, then the joint pmf \\(f(y_1,\\ldots,y_n)=P(Y_1=y_1,…,Y_n=y_n)\\) satisfies the following properties: \\(0\\leq f(y_1,…,y_n )\\leq 1\\), \\(\\sum_{y_1\\in\\mathcal{S}_1}\\cdots \\sum_{y_n\\in\\mathcal{S}_n} f(y_1,…,y_n ) = 1\\), \\(P((Y_1,\\ldots,Y_n)\\in A)=\\sum_{(y_1,\\ldots,y_n) \\in A} f(y_1,\\ldots,y_n)\\). In this context: \\(E(Y_1 \\cdots Y_n)=\\sum_{y_1\\in\\mathcal{S}_1} \\cdots \\sum_{y_n\\in\\mathcal{S}_n}y_1 \\cdots y_n f(y_1,⋯,y_n)\\). In general, \\(E(g(Y_1,\\ldots,Y_n))=\\sum_{y_1\\in\\mathcal{S}_1} \\cdots \\sum_{y_n\\in\\mathcal{S}_n} g(y_1, \\ldots, y_n) f(y_1,⋯,y_n)\\), where \\(g\\) is a function of the random variables. If the random variables are jointly continuous, then \\(f(y_1,\\ldots,y_n)=P(Y_1=y_1,…,Y_n=y_n)\\) is the joint pdf if it satisfies the following properties: \\(f(y_1,…,y_n ) \\geq 0\\), \\(\\int_{y_1\\in\\mathcal{S}_1}\\cdots \\int_{y_n\\in\\mathcal{S}_n} f(y_1,…,y_n ) dy_n \\cdots dy_1 = 1\\), \\(P((Y_1,\\ldots,Y_n)\\in A)=\\int_{(y_1,\\ldots,y_n) \\in A} f(y_1,\\ldots,y_n)\\). In this context: \\(E(Y_1 \\cdots Y_n)=\\int_{y_1\\in\\mathcal{S}_1} \\cdots \\int_{y_n\\in\\mathcal{S}_n} y_1 \\cdots y_n f(y_1,⋯,y_n) dy_n \\cdots dy_1\\). In general, \\(E(g(Y_1,\\ldots,Y_n))=\\int_{y_1\\in\\mathcal{S}_1} \\cdots \\int_{y_n\\in\\mathcal{S}_n} g(y_1, \\ldots, y_n) f(y_1,⋯,y_n) dy_n \\cdots dy_1\\), where \\(g\\) is a function of the random variables. 4.4.2 Marginal distributions If the random variables are jointly discrete, then the marginal pmf of \\(Y_1\\) is \\[f_{Y_1}(y_1)=\\sum_{y_2\\in\\mathcal{S}_2}\\cdots \\sum_{y_n\\in\\mathcal{S}_n} f(y_1,\\ldots,y_n).\\] Similarly, if the random variables are jointly continuous, then the marginal pdf of \\(Y_1\\) is \\[f_{Y_1}(y_1)=\\int_{y_2\\in\\mathcal{S}_2}\\cdots \\int_{y_n\\in\\mathcal{S}_n} f(y_1,\\ldots,y_n) dy_n \\cdots dy_2.\\] 4.5 Joint of continuous RV If \\(X\\) and \\(Y\\) are jointly continuous, \\(f(x,y)\\) is the joint pdf if: f\\((x,y)\\geq 0\\) for all \\((x,y)\\in S\\) \\(\\int_{-\\infty}^\\infty∫_{-infty}^\\infty f(x,y) dx dy=1\\) \\(P\\left((X,Y)\\in A\\right)=\\int \\int_{x,y\\in A} f(x,y)dx dy\\). If \\(X\\) and \\(Y\\) are jointly continuous with joint pdf \\(f(x,y)\\), then the marginal density of \\(X\\), \\(f_X (x)\\) is obtained via the formula \\[f_X (x)=∫_{-\\infty}^\\infty f(x,y) dy\\] \\[E(XY)=\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty xyf(x,y)dy dx.\\] 4.6 Covariance The covariance between random variables \\(Y\\) and \\(Z\\) is \\[cov(Y,Z)=E[(Y-E(Y))(Z-E(Z))]=E(YZ)-E(Y)E(Z).\\] 4.7 Properties of Variance and Covariance Let \\(a\\) and \\(b\\) be scalar constants. Then: \\(E(aY)=aE(Y)\\) \\(E(a+Y)=a+E(Y)\\) \\(E(aY+bZ)=aE(Y)+bE(Z)\\) \\(var(aY)=a^2 var(Y)\\) \\(var(a+Y)=var(Y)\\) \\(cov(aY,bZ)=ab cov(Y,Z).\\) \\(var(Y+Z)=var(Y)+var(Z)+2cov(Y,Z).\\) 4.8 Independence \\(Y\\) and \\(Z\\) are independent if \\(F(y,z)=F_Y (y) F_Z (z).\\) If \\(Y\\) and \\(Z\\) are independent, then: E(YZ)=E(Y)E(Z) cov(Y,Z)=0. 4.9 Properties of random vectors Let \\(\\mathbf{y}=(Y_1,Y_2,\\dots,Y_n )^T\\) be an \\(n×1\\) vector of random variables. \\(\\mathbf{y}\\) is a random vector. A vector is always defined to be a column vector, even if the notation is ambiguous. \\[E(\\mathbf{y})=\\begin{pmatrix}E(Y_1)\\\\E(Y_2)\\\\\\vdots\\\\E(Y_n)\\end{pmatrix}\\] 4.10 Properties of random vectors Let \\(\\mathbf{y}=(Y_1,Y_2,\\dots,Y_n )^T\\) be an \\(n×1\\) vector of random variables. \\(\\mathbf{y}\\) is a random vector. \\[\\begin{aligned} var(\\mathbf{y})= &amp; E(\\mathbf{y}\\mathbf{y}^T )-E(\\mathbf{y})E(\\mathbf{y})^T\\\\ =&amp; \\begin{pmatrix}var(Y_1) &amp; cov(Y_1,Y_2) &amp;\\dots &amp;cov(Y_1,Y_n)\\\\cov(Y_2,Y_1 )&amp;var(Y_2)&amp;\\dots&amp;cov(Y_2,Y_n)\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\ cov(Y_n,Y_1)&amp;cov(Y_n,Y_2)&amp;…&amp;var(Y_n)\\end{pmatrix}\\end{aligned}.\\] 4.11 Important Properties Define: \\(A\\) to be an m×n matrix of constants \\(\\mathbf{x}=(X_1,X_2,…,X_n )^T\\)and \\(\\mathbf{z}=(Z_1,Z_2,…,Z_n )^T\\) to be \\(n×1\\) random vectors. Formally, \\[cov(\\mathbf{x},\\mathbf{y})=E(\\mathbf{x}\\mathbf{y}^T )-E(\\mathbf{x})E(\\mathbf{y})^T.\\] 4.12 Important Properties Additionally: \\(E(A\\mathbf{y})=AE(\\mathbf{y}), E(\\mathbf{y}A^T )=E(\\mathbf{y}) A^T.\\) \\(E(\\mathbf{x}+\\mathbf{y})=E(\\mathbf{x})+E(\\mathbf{y})\\) \\(var(A\\mathbf{y})=A\\ var(\\mathbf{y}) A^T\\) \\(cov(\\mathbf{x}+\\mathbf{y},\\mathbf{z})=cov(\\mathbf{x},\\mathbf{z})+cov(\\mathbf{y},\\mathbf{z})\\) \\(cov(\\mathbf{x},\\mathbf{y}+\\mathbf{z})=cov(\\mathbf{x},\\mathbf{y})+cov(\\mathbf{x},\\mathbf{z})\\) \\(cov(A\\mathbf{x},\\mathbf{y})=A\\ cov(\\mathbf{x},\\mathbf{y})\\text{ and } cov(\\mathbf{x},A\\mathbf{y})=cov(\\mathbf{x},\\mathbf{y}) A^T.\\) 4.13 Important Properties Let \\(\\mathbf{a}\\) is an \\(n×1\\) vector of constants and \\(\\mathbf{0}_{n\\times n}\\) be an \\(n\\times n\\) matrix of zeros, then \\[var(a)=0_{n\\times n},\\] \\[cov(\\mathbf{a},\\mathbf{y})=0_{n\\times n},\\] and \\[var(\\mathbf{a}+\\mathbf{y})=var(\\mathbf{y}).\\] 4.14 Multivariate normal (Gaussian) distribution \\(\\mathbf{y}=(Y_1,\\dots,Y_n )^T\\) has a multivariate normal distribution with mean \\(\\mu\\) (an \\(n\\times 1\\) vector) and covariance \\(\\Sigma\\) (an \\(n\\times n\\) matrix) if the joint pdf is \\[f(\\mathbf{y})=\\frac{1}{(2\\pi)^{n/2} |\\Sigma|^{1/2} } \\exp\\left(-\\frac{1}{2} (\\mathbf{y}-\\mathbf{\\mu})^T \\Sigma^{-1} (\\mathbf{y}-\\mathbf{\\mu})\\right).\\] Note that \\(\\Sigma\\) must be symmetric and positive definite. We would denote this as \\(\\mathbf{y}∼N(\\mathbf{\\mu},\\Sigma)\\). 4.15 Properties Important fact: A linear function of a multivariate normal random vector (i.e., \\(a+A\\mathbf{y}\\)) is also multivariate normal (though it could collapse to a single random variable). Application: Suppose that \\(\\mathbf{y}∼N(\\mu,\\Sigma)\\). For an \\(m\\times n\\) matrix of constants \\(A\\), \\(A\\mathbf{y}∼N(A\\mu,A\\Sigma A^T)\\). 4.16 Example Gasoline is to be stocked in a bulk tank once at the beginning of each week and then sold to individual customers. Let \\(Y_1\\) denote the proportion of the capacity of the bulk tank that is available after the tank is stocked at the beginning of the week. Because of the limited supplies, \\(Y_1\\) varies from week to week. Let \\(Y_2\\) denote the proportion of the capacity of the bulk tank that is sold during the week. Because \\(Y_1\\) and \\(Y_2\\) are both proportions, both variables are between 0 and 1. Further, the amount sold, \\(y_2\\), cannot exceed the amount available, \\(y_1\\). Suppose the joint density function for \\(Y_1\\) and \\(Y_2\\) is given by \\[f(y_1,y_2 )=3y_1;\\ 0≤y_2\\leq y_1\\leq 1.\\] 4.17 Problem 1 Determine \\(P(0\\leq Y_1\\leq 0.5;\\ 0.25\\leq Y_2)\\) 4.18 Problem 2 Determine \\(f_{Y_1 }\\) and \\(f_{Y_2 }\\) 4.19 Problem 3 Determine \\(E(Y_1)\\) and \\(E(Y_2)\\) 4.20 Problem 4 Determine \\(var(Y_1)\\) and \\(var(Y_2)\\) 4.21 Problem 5 Determine \\(E(Y_1 Y_2)\\) 4.22 Problem 6 Determine \\(cov(Y_1,Y_2)\\) 4.23 Problem 7 Determine the mean and variance of \\(a^T y\\), where \\(a=(1,-1)^T\\) and \\(y=(Y_1,Y_2 )^T\\). This is the expectation and variance of the different between the amount of gas available and the amount of gas sold: 4.24 Matrix Differentiation 4.25 Matrix Differentiation 1 Let \\[\\mathbf{y=Ax},\\] where \\(\\mathbf{y}\\) is \\(m\\times 1\\), \\(\\mathbf{x}\\) is \\(n\\times 1\\) , \\(\\mathbf{A}\\) is \\(m\\times n\\), and \\(\\mathbf{A}\\) does not depend on \\(\\mathbf{x}\\), then \\[\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}=A\\] 4.26 Matrix Differentiation 1 (Proof) Since \\(i\\)th element of \\(\\mathbf{y}\\) is given by \\[y_i=\\sum\\limits_{k=1}^{n}a_{ik}x_k,\\] it follows that \\[\\frac{\\partial y_i}{\\partial x_j}=a_{ij}\\] for all \\(i=1,\\dots ,m,\\quad j=1,\\dots ,n\\). Hence \\[\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}=A\\] 4.27 Matrix Differentiation 2 Let the scalar \\(\\alpha\\) be defined by \\[\\alpha =\\mathbf{y}^T\\mathbf{Ax},\\] where \\(\\mathbf{y}\\) is \\(m\\times 1\\), \\(\\mathbf{x}\\) is \\(n\\times 1\\) , \\(\\mathbf{A}\\) is \\(m\\times n\\), and \\(\\mathbf{A}\\) does not depend on \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\), then \\[\\frac{\\partial \\alpha }{\\partial \\mathbf{x}}=\\mathbf{y}^T\\mathbf{A}\\] \\[\\frac{\\partial \\alpha }{\\partial \\mathbf{y}}=\\mathbf{x}^T\\mathbf{A}^T\\] 4.28 Matrix Differentiation 2 (Proof) Define \\(\\mathbf{w}^T=\\mathbf{y}^T\\mathbf{A}\\) and note that \\(\\alpha =\\mathbf{w}^T\\mathbf{x}\\) Hence, \\[\\frac{\\partial \\alpha}{\\partial \\mathbf{x}}=\\mathbf{w}^T=\\mathbf{y}^T\\mathbf{A}.\\] Since \\(\\alpha\\) is a scalar we can write \\[\\alpha =\\alpha^T=\\mathbf{x}^T\\mathbf{A}^T\\mathbf{y}\\] hence, \\[\\frac{\\partial \\alpha }{\\partial \\mathbf{y}}=\\mathbf{x}^T\\mathbf{A}^T\\] 4.29 Matrix Differentiation 3 For the special case in which the scalar \\(\\alpha\\) is given by the quadratic form\\[\\alpha=\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\] where \\(\\mathbf{x}\\) is \\(n\\times 1\\) , \\(\\mathbf{A}\\) is \\(n\\times n\\), and \\(\\mathbf{A}\\) does not depend on \\(\\mathbf{x}\\), then \\[\\frac{\\partial \\alpha}{\\partial \\mathbf{x}}=\\mathbf{x}^T(\\mathbf{A}+\\mathbf{A}^T)\\] 4.30 Matrix Differentiation 3 (Proof) By definition,\\[\\alpha =\\sum\\limits_{j=1}^{n}\\sum\\limits_{i=1}^{n}a_{ij}x_ix_j\\] Differentiating with respect to the \\(k\\)th element of \\(x\\) we have \\[\\frac{\\partial \\alpha}{\\partial x_k}=\\sum\\limits_{j=1}^{n}a_{kj}x_j+\\sum\\limits_{i=1}^{n}a_{ik}x_i\\] for all \\(k=1,\\dots ,n\\), and consequently, \\[\\frac{\\partial \\alpha }{\\partial \\mathbf{x}}=\\mathbf{x}^T\\mathbf{A}^T+\\mathbf{x}^T\\mathbf{A}=\\mathbf{x}^T(A^T+A)\\] 4.31 Matrix Differentiation 3.5 For the special case where \\(\\mathbb{A}\\) is a symmetric matrix and \\[\\alpha=\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\] where \\(\\mathbf{x}\\) is \\(n\\times 1\\) , \\(\\mathbf{A}\\) is \\(n\\times n\\), and \\(\\mathbf{A}\\) does not depend on \\(\\mathbf{x}\\), then \\[\\frac{\\partial \\alpha}{\\partial \\mathbf{x}}=2\\mathbf{x}^T\\mathbb{A}.\\] 4.32 Matrix Differentiation 4 Let the scalar \\(\\alpha\\) be defined by\\[\\alpha =\\mathbf{y}^T\\mathbf{x}\\] where \\(\\mathbf{y}\\) is \\(n\\times 1\\), \\(\\mathbf{x}\\) is \\(n\\times 1\\), and both \\(\\mathbf{y}\\) and \\(\\mathbf{x}\\) are functions of the vector \\(\\mathbf{z}\\). Then \\[\\frac{\\partial \\alpha}{\\partial \\mathbf{z}}=\\mathbf{x}^T\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z}}+\\mathbf{y}^T\\frac{\\partial \\mathbf{x}}{\\partial \\mathbf{z}}\\] 4.33 Matrix Differentiation 4.5 Let the scalar \\(\\alpha\\) be defined by \\[\\alpha =\\mathbf{x}^T\\mathbf{x}\\] where \\(\\mathbf{x}\\) is \\(n\\times 1\\), and \\(\\mathbf{x}\\) is a function of the vector \\(\\mathbf{z}\\). Then \\[\\frac{\\partial \\alpha }{\\partial \\mathbf{z}}=2\\mathbf{x}^T\\frac{\\partial \\mathbf{x}}{\\partial \\mathbf{z}}.\\] "],
["fitting-a-linear-model.html", "Chapter 5 Fitting a linear model 5.1 Simple Linear Regression", " Chapter 5 Fitting a linear model Based on Chapter 2 of LMWR2, Chapter 2 and 3 of ALR4 5.1 Simple Linear Regression The simple linear regression model consists of the mean function \\[E(Y│X=x)=\\beta_0+\\beta_1 x,\\] and variance function \\[var(Y│X=x)=\\sigma^2,\\] where: \\(Y\\) is the response \\(X\\) is a regressor variable \\(\\beta_0\\) and \\(\\beta_1\\) are known as regression parameters or coefficients. "],
["references.html", "References", " References "]
]
